{"cells":[{"cell_type":"code","execution_count":1,"id":"F_XR5ds0_qLR","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":35226,"status":"ok","timestamp":1721757152833,"user":{"displayName":"Amit Pandey","userId":"12754004734397015121"},"user_tz":-330},"id":"F_XR5ds0_qLR","outputId":"ad748039-9edc-4408-8222-4abf4ba73274"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","orgpath = '/content/drive/MyDrive/sayandeep/'"]},{"cell_type":"code","execution_count":2,"id":"3580f1f0","metadata":{"id":"3580f1f0","executionInfo":{"status":"ok","timestamp":1721757160530,"user_tz":-330,"elapsed":4693,"user":{"displayName":"Amit Pandey","userId":"12754004734397015121"}}},"outputs":[],"source":["import os\n","import numpy as np\n","import cv2\n","from tensorflow.keras.utils import Sequence\n","from sklearn.metrics import confusion_matrix, jaccard_score\n","from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler, ReduceLROnPlateau\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, Activation, MaxPooling2D, UpSampling2D, Concatenate\n","from tensorflow.keras.layers import LayerNormalization, MultiHeadAttention\n","import tensorflow.keras.backend as K\n","import tensorflow as tf"]},{"cell_type":"code","execution_count":3,"id":"uF2lDFRG_sL0","metadata":{"id":"uF2lDFRG_sL0","executionInfo":{"status":"ok","timestamp":1721757166699,"user_tz":-330,"elapsed":2,"user":{"displayName":"Amit Pandey","userId":"12754004734397015121"}}},"outputs":[],"source":["FOLDER_PATH = orgpath + 'Processed_Dataset/'\n","image_size = 256\n","batch_size = 64\n","epochs = 50\n","\n","\n","train_path = FOLDER_PATH + \"training/\"\n","validation_path = FOLDER_PATH + \"validation/\"\n","test_path = FOLDER_PATH + \"testing/\""]},{"cell_type":"markdown","id":"kJoz9ETNcpPV","metadata":{"id":"kJoz9ETNcpPV"},"source":["#NEW CODE BELOW\n","\n","Underlying Code is a data generator tailored for tasks where you need segmentation (images and masks).  \n","\n","For modification, change things like:\n","image_path = os.path.join(self.path, \"images\", \"img\", id_name)\n","\n","this means image path = path/images/img/1.png,2.pngetc\n","if you change directory structure take note."]},{"cell_type":"code","execution_count":4,"id":"6pWRLAg-ciWm","metadata":{"id":"6pWRLAg-ciWm","executionInfo":{"status":"ok","timestamp":1721757172018,"user_tz":-330,"elapsed":2,"user":{"displayName":"Amit Pandey","userId":"12754004734397015121"}}},"outputs":[],"source":["#tridibeshoblikheche\n","class DataGen(Sequence):\n","    def __init__(self, ids, path, batch_size=2, image_size=256):\n","        self.ids = ids\n","        self.path = path\n","        self.batch_size = batch_size\n","        self.image_size = image_size\n","        self.on_epoch_end()\n","\n","    def __load__(self, id_name):\n","        image_path = os.path.join(self.path, \"images\", \"img\", id_name)\n","        mask_path = os.path.join(self.path, \"mask\", \"img\", id_name)\n","        image = cv2.imread(image_path)\n","        if image is None or image.size == 0:\n","            return None, None\n","        image = cv2.resize(image, (self.image_size, self.image_size)) / 255.0\n","\n","        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n","        if mask is None or mask.size == 0:\n","            return None, None\n","        mask = cv2.resize(mask, (self.image_size, self.image_size)) / 255.0\n","        mask = np.expand_dims(mask, axis=-1)\n","\n","        return image, mask\n","\n","    def __getitem__(self, index):\n","        files_batch = self.ids[index*self.batch_size : (index+1)*self.batch_size]\n","        images, masks = [], []\n","        for id_name in files_batch:\n","            img, msk = self.__load__(id_name)\n","            if img is not None and msk is not None:\n","                images.append(img)\n","                masks.append(msk)\n","        return np.array(images), np.array(masks)\n","\n","    def on_epoch_end(self):\n","        np.random.shuffle(self.ids)\n","\n","    def __len__(self):\n","        return int(np.ceil(len(self.ids) / float(self.batch_size)))"]},{"cell_type":"code","execution_count":null,"id":"4d5a25d2","metadata":{"id":"4d5a25d2","scrolled":true},"outputs":[],"source":["# # Define the paths\n","# dataset_path = '/content/drive/My Drive/dataset'\n","# image_dirs = ['(0c) Cropped10', '(0i) FolderXGray']\n","# mask_dirs = ['(5a) LumenFarWall', '(5b) MA-FarWall']\n","\n","# # Load images and masks\n","# def load_images_and_masks(image_dirs, mask_dirs, dataset_path, target_size=(256, 256)):\n","#     images = []\n","#     masks = []\n","\n","#     for image_dir, mask_dir in zip(image_dirs, mask_dirs):\n","#         image_path = os.path.join(dataset_path, image_dir)\n","#         mask_path = os.path.join(dataset_path, mask_dir)\n","\n","#         image_files = sorted(os.listdir(image_path))\n","#         mask_files = sorted(os.listdir(mask_path))\n","\n","#         for image_file, mask_file in zip(image_files, mask_files):\n","#             image = cv2.imread(os.path.join(image_path, image_file), cv2.IMREAD_GRAYSCALE)\n","#             mask = np.loadtxt(os.path.join(mask_path, mask_file))\n","\n","#             # Resize image and mask\n","#             image = cv2.resize(image, target_size)\n","#             mask = cv2.resize(mask, target_size)\n","\n","#             # Expand dimensions to match model input\n","#             image = np.expand_dims(image, axis=-1)\n","#             mask = np.expand_dims(mask, axis=-1)\n","\n","#             images.append(image)\n","#             masks.append(mask)\n","\n","#     return np.array(images), np.array(masks)\n","\n","# # Normalize images and masks\n","# def normalize_images_and_masks(images, masks):\n","#     images = images / 255.0\n","#     masks = masks / np.max(masks)\n","#     return images, masks\n","\n","# # Load and preprocess the data\n","# images, masks = load_images_and_masks(image_dirs, mask_dirs, dataset_path)\n","# images, masks = normalize_images_and_masks(images, masks)\n","\n","# # Check the shape of images and masks\n","# print(f'Images shape: {images.shape}')\n","# print(f'Masks shape: {masks.shape}')\n"]},{"cell_type":"code","execution_count":null,"id":"decfe7de","metadata":{"id":"decfe7de"},"outputs":[],"source":["# # Split the data into training and validation sets\n","# X_train, X_val, y_train, y_val = train_test_split(images, masks, test_size=0.2, random_state=42)\n","\n","# # Check the shape of the training and validation sets\n","# print(f'X_train shape: {X_train.shape}')\n","# print(f'X_val shape: {X_val.shape}')\n","# print(f'y_train shape: {y_train.shape}')\n","# print(f'y_val shape: {y_val.shape}')\n"]},{"cell_type":"code","execution_count":null,"id":"lBkWE73aE9zY","metadata":{"id":"lBkWE73aE9zY"},"outputs":[],"source":["# # Data Augmentation\n","# data_gen_args = dict(rotation_range=10,\n","#                      width_shift_range=0.1,\n","#                      height_shift_range=0.1,\n","#                      shear_range=0.1,\n","#                      zoom_range=0.1,\n","#                      horizontal_flip=True,\n","#                      fill_mode='nearest')\n","\n","# image_datagen = ImageDataGenerator(**data_gen_args)\n","# mask_datagen = ImageDataGenerator(**data_gen_args)\n","\n","# image_datagen.fit(X_train, augment=True, seed=42)\n","# mask_datagen.fit(y_train, augment=True, seed=42)\n","\n","# image_generator = image_datagen.flow(X_train, batch_size=8, seed=42)\n","# mask_generator = mask_datagen.flow(y_train, batch_size=8, seed=42)\n","\n","# train_generator = zip(image_generator, mask_generator)\n"]},{"cell_type":"markdown","id":"EMa-l3k6d6tE","metadata":{"id":"EMa-l3k6d6tE"},"source":["#NEW CODE BELOW\n","providing some helper functions, you may just run them. for comparing  models previously made by amit sir, you will need. by me, you will not but good to have.\n","\n","apart from scheduler, dice, and visulaise output, load test, it is redundant (basically, metric functions are redundant but KEEP, custom metrics, cannot load some models for compariosn without them)"]},{"cell_type":"code","execution_count":5,"id":"uGBYdfgCeW1O","metadata":{"id":"uGBYdfgCeW1O","executionInfo":{"status":"ok","timestamp":1721757177743,"user_tz":-330,"elapsed":916,"user":{"displayName":"Amit Pandey","userId":"12754004734397015121"}}},"outputs":[],"source":["def iou(y_true, y_pred, smooth=1):\n","    intersection = K.sum(K.abs(y_true * y_pred), axis=[1,2,3])\n","    union = K.sum(y_true,[1,2,3])+K.sum(y_pred,[1,2,3])-intersection\n","    iou = K.mean((intersection + smooth) / (union + smooth), axis=0)\n","    return iou\n","\n","def F1(y_true, y_pred, smooth=1):\n","    intersection = K.sum(y_true * y_pred, axis=[1, 2, 3])\n","    union = K.sum(y_true, axis=[1, 2, 3]) + K.sum(y_pred, axis=[1, 2, 3])\n","    dice = K.mean((2. * intersection + smooth) / (union + smooth), axis=0)\n","    return dice\n","\n","def dice_coef(y_true, y_pred, smooth = 0.00001):\n","    y_true_f = K.flatten(y_true)\n","    y_pred_f = K.flatten(y_pred)\n","    intersection = K.sum(y_true_f * y_pred_f)\n","    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n","\n","def recall(y_true, y_pred):\n","    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n","    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n","    recall = true_positives / (possible_positives + K.epsilon())\n","    return recall\n","\n","def precision(y_true, y_pred):\n","    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n","    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n","    precision = true_positives / (predicted_positives + K.epsilon())\n","    return precision\n","\n","def dice_coef_loss(y_true, y_pred):\n","    return -dice_coef(y_true, y_pred)\n","\n","def dice_loss(y_true, y_pred):\n","    y_true_f = tf.keras.backend.flatten(y_true)\n","    y_pred_f = tf.keras.backend.flatten(y_pred)\n","    intersection = tf.keras.backend.sum(y_true_f * y_pred_f)\n","    return 1 - (2. * intersection + 1) / (tf.keras.backend.sum(y_true_f) + tf.keras.backend.sum(y_pred_f) + 1)\n","\n","def bce_dice_loss(y_true, y_pred):\n","    bce = tf.keras.losses.BinaryCrossentropy()(y_true, y_pred)\n","    dice = dice_loss(y_true, y_pred)\n","    return bce + dice\n","\n","#till here it is mostly redundant, below is real code but like i said, keep.\n","def load_test_data(batch_size=10):\n","    test_ids = os.listdir(os.path.join(test_path, \"images\", \"img\"))\n","    gen = DataGen(test_ids, test_path, batch_size=batch_size, image_size=image_size)\n","    print(\"Test Data Loaded\")\n","    return gen, len(test_ids)\n","\n","def scheduler(epoch, lr):\n","    if epoch < 30:\n","        lr = 0.001\n","        return lr\n","    if epoch < 50:\n","        return 0.0005\n","    return 0.0001\n","\n","def visualize_output(x, y, y_pred, tot, idx, fig, title_flag=False):\n","    contours1, hierarchy = cv2.findContours(y[0].astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n","    contours2, hierarchy = cv2.findContours(y_pred[0].astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n","    cv2.drawContours(x[0], contours1, -1, (0, 255, 0), 3)\n","    cv2.drawContours(x[0], contours2, -1, (255, 0, 0), 3)\n","    ax = fig.add_subplot(tot, 5, idx)\n","    ax.imshow(np.reshape(x[0], (image_size, image_size, 3)))\n","\n","def evaluate_model(gen, model):\n","    results = {}\n","    y_true_all = []\n","    y_pred_all = []\n","    num_tests = len(gen)\n","    for i in range(num_tests):\n","        x, y_true = gen[i]\n","        y_pred_prob = model.predict(x)\n","        y_pred = (y_pred_prob > 0.8).astype(int)\n","        y_true = (y_true > 0.5).astype(int)\n","        y_true_all.extend(y_true.flatten())\n","        y_pred_all.extend(y_pred.flatten())\n","    y_true_all = np.array(y_true_all)\n","    y_pred_all = np.array(y_pred_all)\n","    tn, fp, fn, tp = confusion_matrix(y_true_all, y_pred_all).ravel()\n","    precision = tp / (tp + fp)\n","    recall = tp / (tp + fn)\n","    specificity = tn / (tn + fp)\n","    iou = jaccard_score(y_true_all, y_pred_all)\n","    out = model.evaluate(gen, steps=num_tests)\n","    last_metric = out[-1]\n","    results = {\n","        'Precision': precision,\n","        'Recall': recall,\n","        'Specificity': specificity,\n","        'IoU': iou,\n","        'Eval Metric': last_metric\n","    }\n","    print(results)"]},{"cell_type":"code","execution_count":null,"id":"VhYQZnv4wJfp","metadata":{"id":"VhYQZnv4wJfp"},"outputs":[],"source":["# inputs = tf.keras.layers.Input(shape=(256, 256, 3))\n","\n","# # Encoder\n","# c1 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n","# c1 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same')(c1)\n","# p1 = tf.keras.layers.MaxPooling2D((2, 2))(c1)\n","\n","# c2 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same')(p1)\n","# c2 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same')(c2)\n","# p2 = tf.keras.layers.MaxPooling2D((2, 2))(c2)\n","\n","# c3 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same')(p2)\n","# c3 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same')(c3)\n","# p3 = tf.keras.layers.MaxPooling2D((2, 2))(c3)\n","\n","# c4 = tf.keras.layers.Conv2D(512, (3, 3), activation='relu', padding='same')(p3)\n","# c4 = tf.keras.layers.Conv2D(512, (3, 3), activation='relu', padding='same')(c4)\n","# p4 = tf.keras.layers.MaxPooling2D((2, 2))(c4)\n","\n","# # Bottleneck\n","# bn = tf.keras.layers.Conv2D(1024, (3, 3), activation='relu', padding='same')(p4)\n","# bn = tf.keras.layers.Conv2D(1024, (3, 3), activation='relu', padding='same')(bn)\n","\n","# # Decoder\n","# u6 = tf.keras.layers.Conv2DTranspose(512, (2, 2), strides=(2, 2), padding='same')(bn)\n","# u6 = tf.keras.layers.concatenate([u6, c4])\n","# c6 = tf.keras.layers.Conv2D(512, (3, 3), activation='relu', padding='same')(u6)\n","# c6 = tf.keras.layers.Conv2D(512, (3, 3), activation='relu', padding='same')(c6)\n","\n","# u7 = tf.keras.layers.Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(c6)\n","# u7 = tf.keras.layers.concatenate([u7, c3])\n","# c7 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same')(u7)\n","# c7 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same')(c7)\n","\n","# u8 = tf.keras.layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c7)\n","# # u8 = tf.keras.layers.concatenate([u8, c2])\n","# c8 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same')(u8)\n","# c8 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same')(c8)\n","\n","# u9 = tf.keras.layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c8)\n","# u9 = tf.keras.layers.concatenate([u9, c1])\n","# c9 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same')(u9)\n","# c9 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same')(c9)\n","\n","# outputs = tf.keras.layers.Conv2D(1, (1, 1), activation='sigmoid')(c9)\n","\n","# model = tf.keras.models.Model(inputs=[inputs], outputs=[outputs])\n","# model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n","#               loss='binary_crossentropy',\n","#               metrics=['accuracy'])\n"]},{"cell_type":"markdown","id":"_O2U3URudg2U","metadata":{"id":"_O2U3URudg2U"},"source":["#NEW CODE BELOW\n","\n","TRAING CODE IS NOT THE BEST. USE THE ONE I GIVE BELOW. DEPRECATED WARNING CAN COME, IN FUTURE MODIFY.\n"]},{"cell_type":"code","execution_count":null,"id":"2zPmV2Codp0L","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":356},"executionInfo":{"elapsed":55338,"status":"error","timestamp":1720462611691,"user":{"displayName":"Amit Pandey","userId":"12754004734397015121"},"user_tz":-330},"id":"2zPmV2Codp0L","outputId":"1ec33276-a039-42c8-acb4-9cc27d52b4b1"},"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-825915b9db87>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mreduce_lr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mReduceLROnPlateau\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfactor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_lr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.00001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mtrain_gen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_gen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1743\u001b[0m         ):\n\u001b[1;32m   1744\u001b[0m             \u001b[0;31m# Creates a `tf.data.Dataset` and handles batch and epoch iteration.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1745\u001b[0;31m             data_handler = data_adapter.get_data_handler(\n\u001b[0m\u001b[1;32m   1746\u001b[0m                 \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1747\u001b[0m                 \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/data_adapter.py\u001b[0m in \u001b[0;36mget_data_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1686\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_ClusterCoordinatorExactEvalDataHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1687\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_ClusterCoordinatorDataHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mDataHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute, pss_evaluation_shards)\u001b[0m\n\u001b[1;32m   1290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1291\u001b[0m         \u001b[0madapter_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_data_adapter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1292\u001b[0;31m         self._adapter = adapter_cls(\n\u001b[0m\u001b[1;32m   1293\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1294\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, shuffle, workers, use_multiprocessing, max_queue_size, model, **kwargs)\u001b[0m\n\u001b[1;32m   1022\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keras_sequence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_enqueuer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m         super().__init__(\n\u001b[0m\u001b[1;32m   1025\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Shuffle is handed in the _make_callable override.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, workers, use_multiprocessing, max_queue_size, model, **kwargs)\u001b[0m\n\u001b[1;32m    881\u001b[0m         \u001b[0;31m# Since we have to know the dtype of the python generator when we build\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m         \u001b[0;31m# the dataset, we have to look at a batch to infer the structure.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 883\u001b[0;31m         \u001b[0mpeek\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_peek_and_restore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    884\u001b[0m         \u001b[0mpeek\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_standardize_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpeek\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    885\u001b[0m         \u001b[0mpeek\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_tensorlike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpeek\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/data_adapter.py\u001b[0m in \u001b[0;36m_peek_and_restore\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1034\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1035\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_peek_and_restore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1036\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1037\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m     def _handle_multiprocessing(\n","\u001b[0;32m<ipython-input-4-e57521c691e2>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mid_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiles_batch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m             \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__load__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmsk\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m                 \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-4-e57521c691e2>\u001b[0m in \u001b[0;36m__load__\u001b[0;34m(self, id_name)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m255.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIMREAD_GRAYSCALE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# # Load training and validation data\n","# train_ids = os.listdir(os.path.join(train_path, \"images\", \"img\",))  #keeep track. do not fuck up directory structure\n","# val_ids = os.listdir(os.path.join(validation_path, \"images\", \"img\",))\n","\n","# train_gen = DataGen(train_ids, train_path, batch_size=batch_size, image_size=image_size)\n","# val_gen = DataGen(val_ids, validation_path, batch_size=batch_size, image_size=image_size)\n","\n","# # Callbacks\n","# checkpoint = ModelCheckpoint('unet_mhsa_best_model.h5', save_best_only=True, monitor='val_loss', mode='min')  #Change model name\n","# lr_scheduler = LearningRateScheduler(scheduler)\n","# reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=0.00001)\n","# # Train the model\n","# history = model.fit(\n","#     train_gen,\n","#     validation_data=val_gen,\n","#     epochs=epochs,\n","#     callbacks=[checkpoint, lr_scheduler, reduce_lr]\n","# )\n","\n","# model.save(orgpath + 'unet_mhsa_final_model') #change model name\n","# print(\"Model saved successfully!\")"]},{"cell_type":"code","execution_count":null,"id":"T0S-retYo9IP","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":373},"id":"T0S-retYo9IP","outputId":"aaf8aa2a-cff6-400b-a73a-899d21771c87","executionInfo":{"status":"error","timestamp":1720462648229,"user_tz":-330,"elapsed":24045,"user":{"displayName":"Amit Pandey","userId":"12754004734397015121"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Test Data Loaded\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-4501ff3e0dc9>\u001b[0m in \u001b[0;36m<cell line: 117>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;31m# Evaluate and visualize the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m \u001b[0mevaluate_and_visualize_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-11-4501ff3e0dc9>\u001b[0m in \u001b[0;36mevaluate_and_visualize_model\u001b[0;34m(gen, model)\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_tests\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0my_pred_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my_pred_prob\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   2653\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2654\u001b[0m                         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2655\u001b[0;31m                         \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2656\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2657\u001b[0m                             \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    916\u001b[0m           )\n\u001b[1;32m    917\u001b[0m       )\n\u001b[0;32m--> 918\u001b[0;31m       return self._concrete_variable_creation_fn._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    919\u001b[0m           \u001b[0mfiltered_flat_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_concrete_variable_creation_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1321\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1322\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1485\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1486\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1487\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1488\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]},{"output_type":"display_data","data":{"text/plain":["<Figure size 1500x13500 with 0 Axes>"]},"metadata":{}}],"source":["# import os\n","# import numpy as np\n","# import matplotlib.pyplot as plt\n","# import cv2\n","# import tensorflow as tf\n","# from keras import backend as K\n","# from sklearn.metrics import confusion_matrix, jaccard_score\n","\n","# # Function to mount Google Drive\n","# from google.colab import drive\n","# drive.mount('/content/drive')\n","\n","# # Path to the model\n","# model_path = '/content/drive/MyDrive/sayandeep/sayandeep_unet'\n","\n","# # Load the model\n","# model = tf.keras.models.load_model(model_path, compile=False)\n","\n","# # Define custom metrics and loss functions if necessary\n","# def iou(y_true, y_pred, smooth=1):\n","#     intersection = K.sum(K.abs(y_true * y_pred), axis=[1,2,3])\n","#     union = K.sum(y_true,[1,2,3]) + K.sum(y_pred,[1,2,3]) - intersection\n","#     iou = K.mean((intersection + smooth) / (union + smooth), axis=0)\n","#     return iou\n","\n","# def F1(y_true, y_pred, smooth=1):\n","#     intersection = K.sum(y_true * y_pred, axis=[1, 2, 3])\n","#     union = K.sum(y_true, axis=[1, 2, 3]) + K.sum(y_pred, axis=[1, 2, 3])\n","#     dice = K.mean((2. * intersection + smooth) / (union + smooth), axis=0)\n","#     return dice\n","\n","# def dice_loss(y_true, y_pred):\n","#     y_true_f = tf.keras.backend.flatten(y_true)\n","#     y_pred_f = tf.keras.backend.flatten(y_pred)\n","#     intersection = tf.keras.backend.sum(y_true_f * y_pred_f)\n","#     return 1 - (2. * intersection + 1) / (tf.keras.backend.sum(y_true_f) + tf.keras.backend.sum(y_pred_f) + 1)\n","\n","# def bce_dice_loss(y_true, y_pred):\n","#     bce = tf.keras.losses.BinaryCrossentropy()(y_true, y_pred)\n","#     dice = dice_loss(y_true, y_pred)\n","#     return bce + dice\n","\n","# # Recompile the model if necessary\n","# model.compile(optimizer='adam', loss=bce_dice_loss, metrics=[iou, F1, 'accuracy'])\n","\n","# # Function to load test data (modify as per your data generator)\n","# def load_test_data(batch_size=10):\n","#     test_ids = os.listdir(os.path.join(test_path, \"images\", \"img\"))\n","#     gen = DataGen(test_ids, test_path, batch_size=batch_size, image_size=image_size)\n","#     print(\"Test Data Loaded\")\n","#     return gen, len(test_ids)\n","\n","# # Function to visualize the output\n","# def visualize_output(x, y, y_pred, tot, idx, fig, title_flag=False):\n","#     contours1, _ = cv2.findContours(y[0].astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n","#     contours2, _ = cv2.findContours(y_pred[0].astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n","#     img_with_contours = x[0].copy()\n","#     cv2.drawContours(img_with_contours, contours1, -1, (0, 255, 0), 3)\n","#     cv2.drawContours(img_with_contours, contours2, -1, (255, 0, 0), 3)\n","#     ax = fig.add_subplot(tot, 3, idx*3 + 1)\n","#     ax.imshow(np.reshape(x[0], (image_size, image_size, 3)))\n","#     if title_flag:\n","#         ax.set_title('Original Image')\n","#     ax = fig.add_subplot(tot, 3, idx*3 + 2)\n","#     ax.imshow(np.reshape(y[0], (image_size, image_size)), cmap='gray')\n","#     if title_flag:\n","#         ax.set_title('True Mask')\n","#     ax = fig.add_subplot(tot, 3, idx*3 + 3)\n","#     ax.imshow(np.reshape(y_pred[0], (image_size, image_size)), cmap='gray')\n","#     if title_flag:\n","#         ax.set_title('Predicted Mask')\n","\n","# # Evaluation and visualization function\n","# def evaluate_and_visualize_model(gen, model):\n","#     results = {}\n","#     y_true_all = []\n","#     y_pred_all = []\n","#     num_tests = len(gen)\n","\n","#     fig = plt.figure(figsize=(15, num_tests * 5))\n","\n","#     for i in range(num_tests):\n","#         x, y_true = gen[i]\n","#         y_pred_prob = model.predict(x)\n","#         y_pred = (y_pred_prob > 0.8).astype(int)\n","#         y_true = (y_true > 0.5).astype(int)\n","\n","#         visualize_output(x, y_true, y_pred, num_tests, i, fig, title_flag=(i == 0))\n","\n","#         y_true_all.extend(y_true.flatten())\n","#         y_pred_all.extend(y_pred.flatten())\n","\n","#     y_true_all = np.array(y_true_all)\n","#     y_pred_all = np.array(y_pred_all)\n","\n","#     tn, fp, fn, tp = confusion_matrix(y_true_all, y_pred_all).ravel()\n","#     precision = tp / (tp + fp)\n","#     recall = tp / (tp + fn)\n","#     specificity = tn / (tn + fp)\n","#     iou = jaccard_score(y_true_all, y_pred_all)\n","#     out = model.evaluate(gen, steps=num_tests)\n","#     last_metric = out[-1]\n","#     results = {\n","#         'Precision': precision,\n","#         'Recall': recall,\n","#         'Specificity': specificity,\n","#         'IoU': iou,\n","#         'Eval Metric': last_metric\n","#     }\n","#     print(results)\n","#     plt.show()\n","\n","# # Load your test data generator\n","# test_gen, num_test_samples = load_test_data(batch_size=10)\n","\n","# # Evaluate and visualize the model\n","# evaluate_and_visualize_model(test_gen, model)\n"]},{"cell_type":"code","source":["# import tensorflow as tf\n","# from tensorflow.keras.layers import GlobalAveragePooling2D, Reshape, Dense, multiply, Conv2D, BatchNormalization, Activation, MaxPooling2D, Concatenate, UpSampling2D, Input\n","# from tensorflow.keras.models import Model\n","\n","# def se_block(input_tensor, reduction_ratio=16):\n","#     channel_axis = -1\n","#     filters = input_tensor.shape[channel_axis]\n","#     se_shape = (1, 1, filters)\n","\n","#     se = GlobalAveragePooling2D()(input_tensor)\n","#     se = Reshape(se_shape)(se)\n","#     se = Dense(filters // reduction_ratio, activation='relu', use_bias=False)(se)\n","#     se = Dense(filters, activation='sigmoid', use_bias=False)(se)\n","\n","#     x = multiply([input_tensor, se])\n","#     return x\n"],"metadata":{"id":"pU7I3bq2vYxz"},"id":"pU7I3bq2vYxz","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# def encoder_block(input_tensor, filters, kernel_size=(3, 3), padding='same', strides=1):\n","#     x = Conv2D(filters, kernel_size, padding=padding, strides=strides)(input_tensor)\n","#     x = BatchNormalization()(x)\n","#     x = Activation('relu')(x)\n","#     x = Conv2D(filters, kernel_size, padding=padding, strides=strides)(x)\n","#     x = BatchNormalization()(x)\n","#     x = Activation('relu')(x)\n","#     x = se_block(x)  # Apply SE block\n","#     return x\n","\n","# def decoder_block(input_tensor, skip_tensor, filters, kernel_size=(3, 3), padding='same', strides=1):\n","#     x = Conv2D(filters, kernel_size, padding=padding, strides=strides)(input_tensor)\n","#     x = BatchNormalization()(x)\n","#     x = Activation('relu')(x)\n","#     x = Conv2D(filters, kernel_size, padding=padding, strides=strides)(x)\n","#     x = BatchNormalization()(x)\n","#     x = Activation('relu')(x)\n","#     x = UpSampling2D(size=(2, 2))(x)\n","#     x = Concatenate()([x, skip_tensor])\n","#     return x\n","\n","# def build_unet_with_se(input_shape, num_classes):\n","#     inputs = Input(input_shape)\n","\n","#     # Encoder\n","#     e1 = encoder_block(inputs, 64)\n","#     p1 = MaxPooling2D(pool_size=(2, 2))(e1)\n","\n","#     e2 = encoder_block(p1, 128)\n","#     p2 = MaxPooling2D(pool_size=(2, 2))(e2)\n","\n","#     e3 = encoder_block(p2, 256)\n","#     p3 = MaxPooling2D(pool_size=(2, 2))(e3)\n","\n","#     e4 = encoder_block(p3, 512)\n","#     p4 = MaxPooling2D(pool_size=(2, 2))(e4)\n","\n","#     # Bottleneck\n","#     b = encoder_block(p4, 1024)\n","\n","#     # Decoder\n","#     d4 = decoder_block(b, e4, 512)\n","#     d3 = decoder_block(d4, e3, 256)\n","#     d2 = decoder_block(d3, e2, 128)\n","#     d1 = decoder_block(d2, e1, 64)\n","\n","#     outputs = Conv2D(num_classes, (1, 1), activation='sigmoid')(d1)\n","\n","#     model = Model(inputs, outputs)\n","#     return model\n"],"metadata":{"id":"yi04wS7wvrQz"},"id":"yi04wS7wvrQz","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# input_shape = (256, 256, 3)  # Adjust this according to your input shape\n","# num_classes = 1  # Adjust this according to your number of classes\n","\n","# # Build the model\n","# model = build_unet_with_se(input_shape, num_classes)\n","\n","# # Compile the model\n","# model.compile(optimizer='adam', loss=bce_dice_loss, metrics=[iou, F1, 'accuracy'])\n","\n","# # Print the model summary\n","# model.summary()\n","\n","# # Load training and validation data\n","# train_path = '/content/drive/My Drive/sayandeep/Processed_Dataset/training'  # Update this with the actual path\n","# validation_path = '/content/drive/My Drive/sayandeep/Processed_Dataset/validation'  # Update this with the actual path\n","# batch_size = 16  # Adjust batch size as needed\n","# image_size = 256  # Adjust image size as needed\n","\n","# train_ids = os.listdir(os.path.join(train_path, \"images\", \"img\"))\n","# val_ids = os.listdir(os.path.join(validation_path, \"images\", \"img\"))\n","\n","# train_gen = DataGen(train_ids, train_path, batch_size=batch_size, image_size=image_size)\n","# val_gen = DataGen(val_ids, validation_path, batch_size=batch_size, image_size=image_size)\n","\n","# # Callbacks\n","# checkpoint = ModelCheckpoint('/content/drive/My Drive/sayandeep/sayandeep_unet.h5', save_best_only=True, monitor='val_loss', mode='min')\n","# lr_scheduler = LearningRateScheduler(scheduler)\n","# reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=0.00001)\n","\n","# # Train the model\n","# history = model.fit(\n","#     train_gen,\n","#     validation_data=val_gen,\n","#     epochs=50,\n","#     callbacks=[checkpoint, lr_scheduler, reduce_lr]\n","# )\n","\n","# # Save the model as TensorFlow SavedModel\n","# model_save_path_tf = '/content/drive/My Drive/sayandeep/sayandeep_unet_attention'\n","# model.save(model_save_path_tf, save_format='tf')\n","# print(f\"Model saved to {model_save_path_tf}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hYohY8U3zgul","outputId":"0ce98180-5cb9-4ad8-cf57-b5180532dcc8"},"id":"hYohY8U3zgul","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model_1\"\n","__________________________________________________________________________________________________\n"," Layer (type)                Output Shape                 Param #   Connected to                  \n","==================================================================================================\n"," input_2 (InputLayer)        [(None, 256, 256, 3)]        0         []                            \n","                                                                                                  \n"," conv2d_19 (Conv2D)          (None, 256, 256, 64)         1792      ['input_2[0][0]']             \n","                                                                                                  \n"," batch_normalization (Batch  (None, 256, 256, 64)         256       ['conv2d_19[0][0]']           \n"," Normalization)                                                                                   \n","                                                                                                  \n"," activation (Activation)     (None, 256, 256, 64)         0         ['batch_normalization[0][0]'] \n","                                                                                                  \n"," conv2d_20 (Conv2D)          (None, 256, 256, 64)         36928     ['activation[0][0]']          \n","                                                                                                  \n"," batch_normalization_1 (Bat  (None, 256, 256, 64)         256       ['conv2d_20[0][0]']           \n"," chNormalization)                                                                                 \n","                                                                                                  \n"," activation_1 (Activation)   (None, 256, 256, 64)         0         ['batch_normalization_1[0][0]'\n","                                                                    ]                             \n","                                                                                                  \n"," global_average_pooling2d (  (None, 64)                   0         ['activation_1[0][0]']        \n"," GlobalAveragePooling2D)                                                                          \n","                                                                                                  \n"," reshape (Reshape)           (None, 1, 1, 64)             0         ['global_average_pooling2d[0][\n","                                                                    0]']                          \n","                                                                                                  \n"," dense (Dense)               (None, 1, 1, 4)              256       ['reshape[0][0]']             \n","                                                                                                  \n"," dense_1 (Dense)             (None, 1, 1, 64)             256       ['dense[0][0]']               \n","                                                                                                  \n"," multiply (Multiply)         (None, 256, 256, 64)         0         ['activation_1[0][0]',        \n","                                                                     'dense_1[0][0]']             \n","                                                                                                  \n"," max_pooling2d_4 (MaxPoolin  (None, 128, 128, 64)         0         ['multiply[0][0]']            \n"," g2D)                                                                                             \n","                                                                                                  \n"," conv2d_21 (Conv2D)          (None, 128, 128, 128)        73856     ['max_pooling2d_4[0][0]']     \n","                                                                                                  \n"," batch_normalization_2 (Bat  (None, 128, 128, 128)        512       ['conv2d_21[0][0]']           \n"," chNormalization)                                                                                 \n","                                                                                                  \n"," activation_2 (Activation)   (None, 128, 128, 128)        0         ['batch_normalization_2[0][0]'\n","                                                                    ]                             \n","                                                                                                  \n"," conv2d_22 (Conv2D)          (None, 128, 128, 128)        147584    ['activation_2[0][0]']        \n","                                                                                                  \n"," batch_normalization_3 (Bat  (None, 128, 128, 128)        512       ['conv2d_22[0][0]']           \n"," chNormalization)                                                                                 \n","                                                                                                  \n"," activation_3 (Activation)   (None, 128, 128, 128)        0         ['batch_normalization_3[0][0]'\n","                                                                    ]                             \n","                                                                                                  \n"," global_average_pooling2d_1  (None, 128)                  0         ['activation_3[0][0]']        \n","  (GlobalAveragePooling2D)                                                                        \n","                                                                                                  \n"," reshape_1 (Reshape)         (None, 1, 1, 128)            0         ['global_average_pooling2d_1[0\n","                                                                    ][0]']                        \n","                                                                                                  \n"," dense_2 (Dense)             (None, 1, 1, 8)              1024      ['reshape_1[0][0]']           \n","                                                                                                  \n"," dense_3 (Dense)             (None, 1, 1, 128)            1024      ['dense_2[0][0]']             \n","                                                                                                  \n"," multiply_1 (Multiply)       (None, 128, 128, 128)        0         ['activation_3[0][0]',        \n","                                                                     'dense_3[0][0]']             \n","                                                                                                  \n"," max_pooling2d_5 (MaxPoolin  (None, 64, 64, 128)          0         ['multiply_1[0][0]']          \n"," g2D)                                                                                             \n","                                                                                                  \n"," conv2d_23 (Conv2D)          (None, 64, 64, 256)          295168    ['max_pooling2d_5[0][0]']     \n","                                                                                                  \n"," batch_normalization_4 (Bat  (None, 64, 64, 256)          1024      ['conv2d_23[0][0]']           \n"," chNormalization)                                                                                 \n","                                                                                                  \n"," activation_4 (Activation)   (None, 64, 64, 256)          0         ['batch_normalization_4[0][0]'\n","                                                                    ]                             \n","                                                                                                  \n"," conv2d_24 (Conv2D)          (None, 64, 64, 256)          590080    ['activation_4[0][0]']        \n","                                                                                                  \n"," batch_normalization_5 (Bat  (None, 64, 64, 256)          1024      ['conv2d_24[0][0]']           \n"," chNormalization)                                                                                 \n","                                                                                                  \n"," activation_5 (Activation)   (None, 64, 64, 256)          0         ['batch_normalization_5[0][0]'\n","                                                                    ]                             \n","                                                                                                  \n"," global_average_pooling2d_2  (None, 256)                  0         ['activation_5[0][0]']        \n","  (GlobalAveragePooling2D)                                                                        \n","                                                                                                  \n"," reshape_2 (Reshape)         (None, 1, 1, 256)            0         ['global_average_pooling2d_2[0\n","                                                                    ][0]']                        \n","                                                                                                  \n"," dense_4 (Dense)             (None, 1, 1, 16)             4096      ['reshape_2[0][0]']           \n","                                                                                                  \n"," dense_5 (Dense)             (None, 1, 1, 256)            4096      ['dense_4[0][0]']             \n","                                                                                                  \n"," multiply_2 (Multiply)       (None, 64, 64, 256)          0         ['activation_5[0][0]',        \n","                                                                     'dense_5[0][0]']             \n","                                                                                                  \n"," max_pooling2d_6 (MaxPoolin  (None, 32, 32, 256)          0         ['multiply_2[0][0]']          \n"," g2D)                                                                                             \n","                                                                                                  \n"," conv2d_25 (Conv2D)          (None, 32, 32, 512)          1180160   ['max_pooling2d_6[0][0]']     \n","                                                                                                  \n"," batch_normalization_6 (Bat  (None, 32, 32, 512)          2048      ['conv2d_25[0][0]']           \n"," chNormalization)                                                                                 \n","                                                                                                  \n"," activation_6 (Activation)   (None, 32, 32, 512)          0         ['batch_normalization_6[0][0]'\n","                                                                    ]                             \n","                                                                                                  \n"," conv2d_26 (Conv2D)          (None, 32, 32, 512)          2359808   ['activation_6[0][0]']        \n","                                                                                                  \n"," batch_normalization_7 (Bat  (None, 32, 32, 512)          2048      ['conv2d_26[0][0]']           \n"," chNormalization)                                                                                 \n","                                                                                                  \n"," activation_7 (Activation)   (None, 32, 32, 512)          0         ['batch_normalization_7[0][0]'\n","                                                                    ]                             \n","                                                                                                  \n"," global_average_pooling2d_3  (None, 512)                  0         ['activation_7[0][0]']        \n","  (GlobalAveragePooling2D)                                                                        \n","                                                                                                  \n"," reshape_3 (Reshape)         (None, 1, 1, 512)            0         ['global_average_pooling2d_3[0\n","                                                                    ][0]']                        \n","                                                                                                  \n"," dense_6 (Dense)             (None, 1, 1, 32)             16384     ['reshape_3[0][0]']           \n","                                                                                                  \n"," dense_7 (Dense)             (None, 1, 1, 512)            16384     ['dense_6[0][0]']             \n","                                                                                                  \n"," multiply_3 (Multiply)       (None, 32, 32, 512)          0         ['activation_7[0][0]',        \n","                                                                     'dense_7[0][0]']             \n","                                                                                                  \n"," max_pooling2d_7 (MaxPoolin  (None, 16, 16, 512)          0         ['multiply_3[0][0]']          \n"," g2D)                                                                                             \n","                                                                                                  \n"," conv2d_27 (Conv2D)          (None, 16, 16, 1024)         4719616   ['max_pooling2d_7[0][0]']     \n","                                                                                                  \n"," batch_normalization_8 (Bat  (None, 16, 16, 1024)         4096      ['conv2d_27[0][0]']           \n"," chNormalization)                                                                                 \n","                                                                                                  \n"," activation_8 (Activation)   (None, 16, 16, 1024)         0         ['batch_normalization_8[0][0]'\n","                                                                    ]                             \n","                                                                                                  \n"," conv2d_28 (Conv2D)          (None, 16, 16, 1024)         9438208   ['activation_8[0][0]']        \n","                                                                                                  \n"," batch_normalization_9 (Bat  (None, 16, 16, 1024)         4096      ['conv2d_28[0][0]']           \n"," chNormalization)                                                                                 \n","                                                                                                  \n"," activation_9 (Activation)   (None, 16, 16, 1024)         0         ['batch_normalization_9[0][0]'\n","                                                                    ]                             \n","                                                                                                  \n"," global_average_pooling2d_4  (None, 1024)                 0         ['activation_9[0][0]']        \n","  (GlobalAveragePooling2D)                                                                        \n","                                                                                                  \n"," reshape_4 (Reshape)         (None, 1, 1, 1024)           0         ['global_average_pooling2d_4[0\n","                                                                    ][0]']                        \n","                                                                                                  \n"," dense_8 (Dense)             (None, 1, 1, 64)             65536     ['reshape_4[0][0]']           \n","                                                                                                  \n"," dense_9 (Dense)             (None, 1, 1, 1024)           65536     ['dense_8[0][0]']             \n","                                                                                                  \n"," multiply_4 (Multiply)       (None, 16, 16, 1024)         0         ['activation_9[0][0]',        \n","                                                                     'dense_9[0][0]']             \n","                                                                                                  \n"," conv2d_29 (Conv2D)          (None, 16, 16, 512)          4719104   ['multiply_4[0][0]']          \n","                                                                                                  \n"," batch_normalization_10 (Ba  (None, 16, 16, 512)          2048      ['conv2d_29[0][0]']           \n"," tchNormalization)                                                                                \n","                                                                                                  \n"," activation_10 (Activation)  (None, 16, 16, 512)          0         ['batch_normalization_10[0][0]\n","                                                                    ']                            \n","                                                                                                  \n"," conv2d_30 (Conv2D)          (None, 16, 16, 512)          2359808   ['activation_10[0][0]']       \n","                                                                                                  \n"," batch_normalization_11 (Ba  (None, 16, 16, 512)          2048      ['conv2d_30[0][0]']           \n"," tchNormalization)                                                                                \n","                                                                                                  \n"," activation_11 (Activation)  (None, 16, 16, 512)          0         ['batch_normalization_11[0][0]\n","                                                                    ']                            \n","                                                                                                  \n"," up_sampling2d (UpSampling2  (None, 32, 32, 512)          0         ['activation_11[0][0]']       \n"," D)                                                                                               \n","                                                                                                  \n"," concatenate_4 (Concatenate  (None, 32, 32, 1024)         0         ['up_sampling2d[0][0]',       \n"," )                                                                   'multiply_3[0][0]']          \n","                                                                                                  \n"," conv2d_31 (Conv2D)          (None, 32, 32, 256)          2359552   ['concatenate_4[0][0]']       \n","                                                                                                  \n"," batch_normalization_12 (Ba  (None, 32, 32, 256)          1024      ['conv2d_31[0][0]']           \n"," tchNormalization)                                                                                \n","                                                                                                  \n"," activation_12 (Activation)  (None, 32, 32, 256)          0         ['batch_normalization_12[0][0]\n","                                                                    ']                            \n","                                                                                                  \n"," conv2d_32 (Conv2D)          (None, 32, 32, 256)          590080    ['activation_12[0][0]']       \n","                                                                                                  \n"," batch_normalization_13 (Ba  (None, 32, 32, 256)          1024      ['conv2d_32[0][0]']           \n"," tchNormalization)                                                                                \n","                                                                                                  \n"," activation_13 (Activation)  (None, 32, 32, 256)          0         ['batch_normalization_13[0][0]\n","                                                                    ']                            \n","                                                                                                  \n"," up_sampling2d_1 (UpSamplin  (None, 64, 64, 256)          0         ['activation_13[0][0]']       \n"," g2D)                                                                                             \n","                                                                                                  \n"," concatenate_5 (Concatenate  (None, 64, 64, 512)          0         ['up_sampling2d_1[0][0]',     \n"," )                                                                   'multiply_2[0][0]']          \n","                                                                                                  \n"," conv2d_33 (Conv2D)          (None, 64, 64, 128)          589952    ['concatenate_5[0][0]']       \n","                                                                                                  \n"," batch_normalization_14 (Ba  (None, 64, 64, 128)          512       ['conv2d_33[0][0]']           \n"," tchNormalization)                                                                                \n","                                                                                                  \n"," activation_14 (Activation)  (None, 64, 64, 128)          0         ['batch_normalization_14[0][0]\n","                                                                    ']                            \n","                                                                                                  \n"," conv2d_34 (Conv2D)          (None, 64, 64, 128)          147584    ['activation_14[0][0]']       \n","                                                                                                  \n"," batch_normalization_15 (Ba  (None, 64, 64, 128)          512       ['conv2d_34[0][0]']           \n"," tchNormalization)                                                                                \n","                                                                                                  \n"," activation_15 (Activation)  (None, 64, 64, 128)          0         ['batch_normalization_15[0][0]\n","                                                                    ']                            \n","                                                                                                  \n"," up_sampling2d_2 (UpSamplin  (None, 128, 128, 128)        0         ['activation_15[0][0]']       \n"," g2D)                                                                                             \n","                                                                                                  \n"," concatenate_6 (Concatenate  (None, 128, 128, 256)        0         ['up_sampling2d_2[0][0]',     \n"," )                                                                   'multiply_1[0][0]']          \n","                                                                                                  \n"," conv2d_35 (Conv2D)          (None, 128, 128, 64)         147520    ['concatenate_6[0][0]']       \n","                                                                                                  \n"," batch_normalization_16 (Ba  (None, 128, 128, 64)         256       ['conv2d_35[0][0]']           \n"," tchNormalization)                                                                                \n","                                                                                                  \n"," activation_16 (Activation)  (None, 128, 128, 64)         0         ['batch_normalization_16[0][0]\n","                                                                    ']                            \n","                                                                                                  \n"," conv2d_36 (Conv2D)          (None, 128, 128, 64)         36928     ['activation_16[0][0]']       \n","                                                                                                  \n"," batch_normalization_17 (Ba  (None, 128, 128, 64)         256       ['conv2d_36[0][0]']           \n"," tchNormalization)                                                                                \n","                                                                                                  \n"," activation_17 (Activation)  (None, 128, 128, 64)         0         ['batch_normalization_17[0][0]\n","                                                                    ']                            \n","                                                                                                  \n"," up_sampling2d_3 (UpSamplin  (None, 256, 256, 64)         0         ['activation_17[0][0]']       \n"," g2D)                                                                                             \n","                                                                                                  \n"," concatenate_7 (Concatenate  (None, 256, 256, 128)        0         ['up_sampling2d_3[0][0]',     \n"," )                                                                   'multiply[0][0]']            \n","                                                                                                  \n"," conv2d_37 (Conv2D)          (None, 256, 256, 1)          129       ['concatenate_7[0][0]']       \n","                                                                                                  \n","==================================================================================================\n","Total params: 29992001 (114.41 MB)\n","Trainable params: 29980225 (114.37 MB)\n","Non-trainable params: 11776 (46.00 KB)\n","__________________________________________________________________________________________________\n","Epoch 1/50\n","  2/307 [..............................] - ETA: 28s - loss: 1.5871 - iou: 0.0170 - F1: 0.0330 - accuracy: 0.6506    "]}]},{"cell_type":"code","source":["# import matplotlib.pyplot as plt\n","# import numpy as np\n","# import tensorflow as tf\n","# from sklearn.metrics import confusion_matrix, jaccard_score\n","# from tensorflow.keras.utils import plot_model\n","\n","# # Function to evaluate the model\n","# def evaluate_model(model, test_gen):\n","#     results = {}\n","#     y_true_all = []\n","#     y_pred_all = []\n","#     num_tests = len(test_gen)\n","#     for i in range(num_tests):\n","#         x, y_true = test_gen[i]\n","#         y_pred_prob = model.predict(x)\n","#         y_pred = (y_pred_prob > 0.8).astype(int)\n","#         y_true = (y_true > 0.5).astype(int)\n","#         y_true_all.extend(y_true.flatten())\n","#         y_pred_all.extend(y_pred.flatten())\n","#     y_true_all = np.array(y_true_all)\n","#     y_pred_all = np.array(y_pred_all)\n","#     tn, fp, fn, tp = confusion_matrix(y_true_all, y_pred_all).ravel()\n","#     precision = tp / (tp + fp)\n","#     recall = tp / (tp + fn)\n","#     specificity = tn / (tn + fp)\n","#     iou = jaccard_score(y_true_all, y_pred_all)\n","#     out = model.evaluate(test_gen, steps=num_tests)\n","#     last_metric = out[-1]\n","#     results = {\n","#         'Precision': precision,\n","#         'Recall': recall,\n","#         'Specificity': specificity,\n","#         'IoU': iou,\n","#         'Eval Metric': last_metric\n","#     }\n","#     print(results)\n","#     return results\n","\n","# # Function to visualize model performance\n","# def plot_metrics(history):\n","#     # Plot training & validation loss values\n","#     plt.figure(figsize=(12, 4))\n","#     plt.subplot(1, 2, 1)\n","#     plt.plot(history.history['loss'])\n","#     plt.plot(history.history['val_loss'])\n","#     plt.title('Model loss')\n","#     plt.ylabel('Loss')\n","#     plt.xlabel('Epoch')\n","#     plt.legend(['Train', 'Validation'], loc='upper left')\n","\n","#     # Plot training & validation accuracy values\n","#     plt.subplot(1, 2, 2)\n","#     plt.plot(history.history['accuracy'])\n","#     plt.plot(history.history['val_accuracy'])\n","#     plt.title('Model accuracy')\n","#     plt.ylabel('Accuracy')\n","#     plt.xlabel('Epoch')\n","#     plt.legend(['Train', 'Validation'], loc='upper left')\n","\n","#     plt.show()\n","\n","# # Function to visualize predictions\n","# def visualize_predictions(model, test_gen, num_images=5):\n","#     for i in range(num_images):\n","#         x, y_true = test_gen[i]\n","#         y_pred_prob = model.predict(x)\n","#         y_pred = (y_pred_prob > 0.8).astype(int)\n","\n","#         plt.figure(figsize=(15, 5))\n","\n","#         # Original Image\n","#         plt.subplot(1, 3, 1)\n","#         plt.imshow(np.reshape(x[0], (image_size, image_size, 3)))\n","#         plt.title('Original Image')\n","\n","#         # Ground Truth\n","#         plt.subplot(1, 3, 2)\n","#         plt.imshow(np.reshape(y_true[0], (image_size, image_size)), cmap='gray')\n","#         plt.title('Ground Truth')\n","\n","#         # Predicted Mask\n","#         plt.subplot(1, 3, 3)\n","#         plt.imshow(np.reshape(y_pred[0], (image_size, image_size)), cmap='gray')\n","#         plt.title('Predicted Mask')\n","\n","#         plt.show()\n","\n","# # Load the saved model\n","# model_save_path_tf = '/content/drive/My Drive/sayandeep/sayandeep_unet_attention'\n","# model = tf.keras.models.load_model(model_save_path_tf, custom_objects={'bce_dice_loss': bce_dice_loss, 'iou': iou, 'F1': F1})\n","\n","# # Load test data\n","# test_path = '/content/drive/My Drive/sayandeep/Processed_Dataset/testing'\n","# batch_size = 16  # Adjust batch size as needed\n","# image_size = 256  # Adjust image size as needed\n","\n","# test_ids = os.listdir(os.path.join(test_path,\"images\",\"img\",))\n","# test_gen = DataGen(test_ids, test_path, batch_size=batch_size, image_size=image_size)\n","\n","# # Evaluate the model\n","# results = evaluate_model(model, test_gen)\n","\n","# # Plot the training history\n","# plot_metrics(history)\n","\n","# # Visualize predictions\n","# visualize_predictions(model, test_gen, num_images=5)\n"],"metadata":{"id":"yDFPbhLxSj1Y","colab":{"base_uri":"https://localhost:8080/","height":370},"executionInfo":{"status":"error","timestamp":1720463108939,"user_tz":-330,"elapsed":12181,"user":{"displayName":"Amit Pandey","userId":"12754004734397015121"}},"outputId":"0f0baaff-f042-4d0b-e9f9-b8b307fd76c3"},"id":"yDFPbhLxSj1Y","execution_count":null,"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-6a17fe2818d6>\u001b[0m in \u001b[0;36m<cell line: 101>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;31m# Evaluate the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;31m# Plot the training history\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-10-6a17fe2818d6>\u001b[0m in \u001b[0;36mevaluate_model\u001b[0;34m(model, test_gen)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mnum_tests\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_tests\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_gen\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0my_pred_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my_pred_prob\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-5-e57521c691e2>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mid_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiles_batch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m             \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__load__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmsk\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m                 \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-5-e57521c691e2>\u001b[0m in \u001b[0;36m__load__\u001b[0;34m(self, id_name)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mimage_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"images\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"img\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mmask_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"mask\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"img\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["# import tensorflow as tf\n","# from tensorflow.keras.layers import Conv2D, Dense, Activation, Reshape, multiply, Add, GlobalAveragePooling2D, GlobalMaxPooling2D, Concatenate, Lambda\n","\n","# def cbam_block(input_tensor, reduction_ratio=16):\n","#     channel_axis = -1\n","#     filters = input_tensor.shape[channel_axis]\n","\n","#     # Channel Attention\n","#     avg_pool = GlobalAveragePooling2D()(input_tensor)\n","#     avg_pool = Reshape((1, 1, filters))(avg_pool)\n","#     avg_pool = Dense(filters // reduction_ratio, activation='relu', kernel_initializer='he_normal', use_bias=False)(avg_pool)\n","#     avg_pool = Dense(filters, activation='sigmoid', kernel_initializer='he_normal', use_bias=False)(avg_pool)\n","\n","#     max_pool = GlobalMaxPooling2D()(input_tensor)\n","#     max_pool = Reshape((1, 1, filters))(max_pool)\n","#     max_pool = Dense(filters // reduction_ratio, activation='relu', kernel_initializer='he_normal', use_bias=False)(max_pool)\n","#     max_pool = Dense(filters, activation='sigmoid', kernel_initializer='he_normal', use_bias=False)(max_pool)\n","\n","#     channel_attention = Add()([avg_pool, max_pool])\n","\n","#     x = multiply([input_tensor, channel_attention])\n","\n","#     # Spatial Attention\n","#     avg_pool = Lambda(lambda x: tf.reduce_mean(x, axis=-1, keepdims=True))(x)\n","#     max_pool = Lambda(lambda x: tf.reduce_max(x, axis=-1, keepdims=True))(x)\n","#     spatial_attention = Concatenate(axis=-1)([avg_pool, max_pool])\n","#     spatial_attention = Conv2D(1, (7, 7), padding='same', activation='sigmoid', kernel_initializer='he_normal', use_bias=False)(spatial_attention)\n","\n","#     x = multiply([x, spatial_attention])\n","\n","#     return x\n"],"metadata":{"id":"NnEKunyltTW4"},"id":"NnEKunyltTW4","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# from tensorflow.keras.layers import Input, MaxPooling2D, Concatenate, UpSampling2D, BatchNormalization, Activation\n","\n","# def encoder_block(input_tensor, filters, kernel_size=(3, 3), padding='same', strides=1):\n","#     x = Conv2D(filters, kernel_size, padding=padding, strides=strides)(input_tensor)\n","#     x = BatchNormalization()(x)\n","#     x = Activation('relu')(x)\n","#     x = Conv2D(filters, kernel_size, padding=padding, strides=strides)(x)\n","#     x = BatchNormalization()(x)\n","#     x = Activation('relu')(x)\n","#     x = cbam_block(x)  # Apply CBAM block\n","#     return x\n","\n","# def decoder_block(input_tensor, skip_tensor, filters, kernel_size=(3, 3), padding='same', strides=1):\n","#     x = Conv2D(filters, kernel_size, padding=padding, strides=strides)(input_tensor)\n","#     x = BatchNormalization()(x)\n","#     x = Activation('relu')(x)\n","#     x = Conv2D(filters, kernel_size, padding=padding, strides=strides)(x)\n","#     x = BatchNormalization()(x)\n","#     x = Activation('relu')(x)\n","#     x = UpSampling2D(size=(2, 2))(x)\n","#     x = Concatenate()([x, skip_tensor])\n","#     return x\n"],"metadata":{"id":"KyvacsBaOoRK"},"id":"KyvacsBaOoRK","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# from tensorflow.keras.models import Model\n","\n","# def build_unet_with_cbam(input_shape, num_classes):\n","#     inputs = Input(input_shape)\n","\n","#     # Encoder\n","#     e1 = encoder_block(inputs, 64)\n","#     p1 = MaxPooling2D(pool_size=(2, 2))(e1)\n","\n","#     e2 = encoder_block(p1, 128)\n","#     p2 = MaxPooling2D(pool_size=(2, 2))(e2)\n","\n","#     e3 = encoder_block(p2, 256)\n","#     p3 = MaxPooling2D(pool_size=(2, 2))(e3)\n","\n","#     e4 = encoder_block(p3, 512)\n","#     p4 = MaxPooling2D(pool_size=(2, 2))(e4)\n","\n","#     # Bottleneck\n","#     b = encoder_block(p4, 1024)\n","\n","#     # Decoder\n","#     d4 = decoder_block(b, e4, 512)\n","#     d3 = decoder_block(d4, e3, 256)\n","#     d2 = decoder_block(d3, e2, 128)\n","#     d1 = decoder_block(d2, e1, 64)\n","\n","#     outputs = Conv2D(num_classes, (1, 1), activation='sigmoid')(d1)\n","\n","#     model = Model(inputs, outputs)\n","#     return model\n"],"metadata":{"id":"93OUPzA2OulY"},"id":"93OUPzA2OulY","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# # Set input shape and number of classes\n","# input_shape = (256, 256, 3)  # Adjust this according to your input shape\n","# num_classes = 1  # Adjust this according to your number of classes\n","\n","# # Build the model\n","# model = build_unet_with_cbam(input_shape, num_classes)\n","\n","# # Compile the model\n","# model.compile(optimizer='adam', loss=bce_dice_loss, metrics=[iou, F1, 'accuracy'])\n","\n","# # Print the model summary\n","# model.summary()\n","\n","# # Load training and validation data\n","# train_path = '/content/drive/My Drive/sayandeep/Processed_Dataset/training'  # Update this with the actual path\n","# validation_path = '/content/drive/My Drive/sayandeep/Processed_Dataset/validation'  # Update this with the actual path\n","# batch_size = 16  # Adjust batch size as needed\n","# image_size = 256  # Adjust image size as needed\n","\n","# train_ids = os.listdir(os.path.join(train_path, \"images\", \"img\"))\n","# val_ids = os.listdir(os.path.join(validation_path, \"images\", \"img\"))\n","\n","# train_gen = DataGen(train_ids, train_path, batch_size=batch_size, image_size=image_size)\n","# val_gen = DataGen(val_ids, validation_path, batch_size=batch_size, image_size=image_size)\n","\n","# # Callbacks\n","# checkpoint = ModelCheckpoint('/content/drive/My Drive/sayandeep/sayandeep_unet_cbam.h5', save_best_only=True, monitor='val_loss', mode='min')\n","# lr_scheduler = LearningRateScheduler(scheduler)\n","# reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=0.00001)\n","\n","# # Train the model\n","# history = model.fit(\n","#     train_gen,\n","#     validation_data=val_gen,\n","#     epochs=50,\n","#     callbacks=[checkpoint, lr_scheduler, reduce_lr]\n","# )\n","\n","# # Save the model as TensorFlow SavedModel\n","# model_save_path_tf = '/content/drive/My Drive/sayandeep/sayandeep_cbam_unet'\n","# model.save(model_save_path_tf, save_format='tf')\n","# print(f\"Model saved to {model_save_path_tf}\")\n"],"metadata":{"id":"VQux6eqGOyxd"},"id":"VQux6eqGOyxd","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# import tensorflow as tf\n","# import os\n","# import numpy as np\n","# import matplotlib.pyplot as plt\n","# from sklearn.metrics import confusion_matrix, jaccard_score\n","# from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","# # Function to load the saved model\n","# def load_model(model_save_path_tf):\n","#     model = tf.keras.models.load_model(model_save_path_tf, custom_objects={'bce_dice_loss': bce_dice_loss, 'iou': iou, 'F1': F1})\n","#     print(f\"Model loaded from {model_save_path_tf}\")\n","#     return model\n","\n","# # Function to evaluate the model\n","# def evaluate_model(model, test_gen):\n","#     results = {}\n","#     y_true_all = []\n","#     y_pred_all = []\n","#     num_tests = len(test_gen)\n","#     for i in range(num_tests):\n","#         x, y_true = test_gen[i]\n","#         y_pred_prob = model.predict(x)\n","#         y_pred = (y_pred_prob > 0.8).astype(int)\n","#         y_true = (y_true > 0.5).astype(int)\n","#         y_true_all.extend(y_true.flatten())\n","#         y_pred_all.extend(y_pred.flatten())\n","#     y_true_all = np.array(y_true_all)\n","#     y_pred_all = np.array(y_pred_all)\n","#     tn, fp, fn, tp = confusion_matrix(y_true_all, y_pred_all).ravel()\n","#     precision = tp / (tp + fp)\n","#     recall = tp / (tp + fn)\n","#     specificity = tn / (tn + fp)\n","#     iou = jaccard_score(y_true_all, y_pred_all)\n","#     out = model.evaluate(test_gen, steps=num_tests)\n","#     last_metric = out[-1]\n","#     results = {\n","#         'Precision': precision,\n","#         'Recall': recall,\n","#         'Specificity': specificity,\n","#         'IoU': iou,\n","#         'Eval Metric': last_metric\n","#     }\n","#     print(results)\n","#     return results\n","\n","# # Function to visualize model performance\n","# def plot_metrics(history):\n","#     # Plot training & validation loss values\n","#     plt.figure(figsize=(12, 4))\n","#     plt.subplot(1, 2, 1)\n","#     plt.plot(history.history['loss'])\n","#     plt.plot(history.history['val_loss'])\n","#     plt.title('Model loss')\n","#     plt.ylabel('Loss')\n","#     plt.xlabel('Epoch')\n","#     plt.legend(['Train', 'Validation'], loc='upper left')\n","\n","#     # Plot training & validation accuracy values\n","#     plt.subplot(1, 2, 2)\n","#     plt.plot(history.history['accuracy'])\n","#     plt.plot(history.history['val_accuracy'])\n","#     plt.title('Model accuracy')\n","#     plt.ylabel('Accuracy')\n","#     plt.xlabel('Epoch')\n","#     plt.legend(['Train', 'Validation'], loc='upper left')\n","\n","#     plt.show()\n","\n","# # Function to visualize predictions\n","# def visualize_predictions(model, test_gen, num_images=5):\n","#     for i in range(num_images):\n","#         x, y_true = test_gen[i]\n","#         y_pred_prob = model.predict(x)\n","#         y_pred = (y_pred_prob > 0.8).astype(int)\n","\n","#         plt.figure(figsize=(15, 5))\n","\n","#         # Original Image\n","#         plt.subplot(1, 3, 1)\n","#         plt.imshow(np.reshape(x[0], (image_size, image_size, 3)))\n","#         plt.title('Original Image')\n","\n","#         # Ground Truth\n","#         plt.subplot(1, 3, 2)\n","#         plt.imshow(np.reshape(y_true[0], (image_size, image_size)), cmap='gray')\n","#         plt.title('Ground Truth')\n","\n","#         # Predicted Mask\n","#         plt.subplot(1, 3, 3)\n","#         plt.imshow(np.reshape(y_pred[0], (image_size, image_size)), cmap='gray')\n","#         plt.title('Predicted Mask')\n","\n","#         plt.show()\n","\n","# # Load the saved model\n","# model_save_path_tf = '/content/drive/My Drive/sayandeep/sayandeep_cbam_unet'\n","# model = load_model(model_save_path_tf)\n","\n","# # Load test data\n","# test_path = '/content/drive/My Drive/sayandeep/Processed_Dataset/testing'  # Update this with the actual path\n","# batch_size = 16  # Adjust batch size as needed\n","# image_size = 256  # Adjust image size as needed\n","\n","# test_ids = os.listdir(os.path.join(test_path, \"images\", \"img\"))\n","# test_gen = DataGen(test_ids, test_path, batch_size=batch_size, image_size=image_size)\n","\n","# # Evaluate the model\n","# results = evaluate_model(model, test_gen)\n","\n","# # Visualize predictions\n","# visualize_predictions(model, test_gen, num_images=5)\n"],"metadata":{"id":"SFnm9fYA8Zqd","colab":{"base_uri":"https://localhost:8080/","height":370},"executionInfo":{"status":"error","timestamp":1720463141720,"user_tz":-330,"elapsed":15885,"user":{"displayName":"Amit Pandey","userId":"12754004734397015121"}},"outputId":"ef88a1ed-fd20-4546-ede2-852982464baa"},"id":"SFnm9fYA8Zqd","execution_count":null,"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-14-8c35d4a00848>\u001b[0m in \u001b[0;36m<cell line: 97>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;31m# Load the saved model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0mmodel_save_path_tf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/drive/My Drive/sayandeep/sayandeep_cbam_unet'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_save_path_tf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;31m# Load test data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-14-8c35d4a00848>\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(model_save_path_tf)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Function to load the saved model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_save_path_tf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_save_path_tf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'bce_dice_loss'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbce_dice_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'iou'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0miou\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'F1'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mF1\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Model loaded from {model_save_path_tf}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/saving/saving_api.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode, **kwargs)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m     \u001b[0;31m# Legacy case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m     return legacy_sm_saving_lib.load_model(\n\u001b[0m\u001b[1;32m    263\u001b[0m         \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m     )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/saving/legacy/save.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m                             return saved_model_load.load(\n\u001b[0m\u001b[1;32m    240\u001b[0m                                 \u001b[0mfilepath_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m                             )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/saving/legacy/saved_model/load.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(path, compile, options)\u001b[0m\n\u001b[1;32m    143\u001b[0m             \u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Trying to load ShardedVariables\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         )\n\u001b[0;32m--> 145\u001b[0;31m         loaded = tf.__internal__.saved_model.load_partial(\n\u001b[0m\u001b[1;32m    146\u001b[0m             \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnodes_to_load\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/saved_model/load.py\u001b[0m in \u001b[0;36mload_partial\u001b[0;34m(export_dir, filters, tags, options)\u001b[0m\n\u001b[1;32m   1041\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1043\u001b[0;31m         loader = Loader(object_graph_proto, saved_model_proto, export_dir,\n\u001b[0m\u001b[1;32m   1044\u001b[0m                         ckpt_options, options, filters)\n\u001b[1;32m   1045\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNotFoundError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/saved_model/load.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, object_graph_proto, saved_model_proto, export_dir, ckpt_options, save_options, filters)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msave_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_skip_checkpoint\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_restore_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nodes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCapturableResource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/saved_model/load.py\u001b[0m in \u001b[0;36m_restore_checkpoint\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m       \u001b[0mload_status\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_nontrivial_match\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m       \u001b[0mload_status\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariables_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_checkpoint_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m       \u001b[0mload_status\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_existing_objects_matched\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m     \u001b[0mckpt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_status\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_checkpoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/checkpoint/checkpoint.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, save_path, options)\u001b[0m\n\u001b[1;32m   1477\u001b[0m         saveables_cache=self._saveables_cache)\n\u001b[1;32m   1478\u001b[0m     restore_lib.CheckpointPosition(\n\u001b[0;32m-> 1479\u001b[0;31m         \u001b[0mcheckpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproto_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_view\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1480\u001b[0m                                                    reader)\n\u001b[1;32m   1481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/checkpoint/restore.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, trackable, reader)\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;31m# This object's correspondence with a checkpointed object is new, so\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;31m# process deferred restorations for it and its dependencies.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mrestore_ops\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_restore_descendants\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrestore_ops\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_checkpoint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_restore_ops\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrestore_ops\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/checkpoint/restore.py\u001b[0m in \u001b[0;36m_restore_descendants\u001b[0;34m(self, reader)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m     restore_ops.extend(\n\u001b[0;32m--> 463\u001b[0;31m         current_position.checkpoint.restore_saveables(\n\u001b[0m\u001b[1;32m    464\u001b[0m             \u001b[0mtensor_saveables\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m             \u001b[0mpython_positions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/checkpoint/checkpoint.py\u001b[0m in \u001b[0;36mrestore_saveables\u001b[0;34m(self, tensor_saveables, python_positions, registered_savers, reader)\u001b[0m\n\u001b[1;32m    377\u001b[0m       new_restore_ops = functional_saver.MultiDeviceSaver.from_saveables(\n\u001b[1;32m    378\u001b[0m           \u001b[0mflat_saveables\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m           registered_savers).restore(self.save_path_tensor, self.options)\n\u001b[0m\u001b[1;32m    380\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrestore_op\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_restore_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/checkpoint/functional_saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, file_prefix, options)\u001b[0m\n\u001b[1;32m    497\u001b[0m       \u001b[0mrestore_ops\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_function_restore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 499\u001b[0;31m       \u001b[0mrestore_ops\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrestore_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mrestore_ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/checkpoint/functional_saver.py\u001b[0m in \u001b[0;36mrestore_fn\u001b[0;34m()\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m           \u001b[0;31m# Load values from checkpoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m           \u001b[0mrestored_tensor_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m           \u001b[0;31m# Map restored tensors to the corresponding restore_fn, and see if all\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/checkpoint/functional_saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, file_prefix, options)\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0mrestore_device\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_io_device\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m\"cpu:0\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrestore_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m       restored_tensors = io_ops.restore_v2(\n\u001b[0m\u001b[1;32m    115\u001b[0m           file_prefix, tensor_names, slice_specs, tensor_dtypes)\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/gen_io_ops.py\u001b[0m in \u001b[0;36mrestore_v2\u001b[0;34m(prefix, tensor_names, shape_and_slices, dtypes, name)\u001b[0m\n\u001b[1;32m   1509\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m       return restore_v2_eager_fallback(\n\u001b[0m\u001b[1;32m   1512\u001b[0m           \u001b[0mprefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape_and_slices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m           ctx=_ctx)\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/gen_io_ops.py\u001b[0m in \u001b[0;36mrestore_v2_eager_fallback\u001b[0;34m(prefix, tensor_names, shape_and_slices, dtypes, name, ctx)\u001b[0m\n\u001b[1;32m   1548\u001b[0m   \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape_and_slices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1549\u001b[0m   \u001b[0m_attrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"dtypes\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1550\u001b[0;31m   _result = _execute.execute(b\"RestoreV2\", len(dtypes), inputs=_inputs_flat,\n\u001b[0m\u001b[1;32m   1551\u001b[0m                              attrs=_attrs, ctx=ctx, name=name)\n\u001b[1;32m   1552\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmust_record_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras import layers, models\n","import os\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import confusion_matrix, jaccard_score\n","from tensorflow.keras.preprocessing.image import load_img, img_to_array\n","from tensorflow.keras.utils import Sequence\n","from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler, ReduceLROnPlateau\n"],"metadata":{"id":"WKLAMc39F6hC"},"id":"WKLAMc39F6hC","execution_count":null,"outputs":[]},{"cell_type":"code","source":["def cbam_block(input_tensor, ratio=8):\n","    channel = input_tensor.shape[-1]\n","    shared_layer_one = layers.Dense(channel // ratio, activation='relu', kernel_initializer='he_normal', use_bias=True, bias_initializer='zeros')\n","    shared_layer_two = layers.Dense(channel, kernel_initializer='he_normal', use_bias=True, bias_initializer='zeros')\n","\n","    avg_pool = layers.GlobalAveragePooling2D()(input_tensor)\n","    avg_pool = layers.Reshape((1, 1, channel))(avg_pool)\n","    avg_pool = shared_layer_one(avg_pool)\n","    avg_pool = shared_layer_two(avg_pool)\n","\n","    max_pool = layers.GlobalMaxPooling2D()(input_tensor)\n","    max_pool = layers.Reshape((1, 1, channel))(max_pool)\n","    max_pool = shared_layer_one(max_pool)\n","    max_pool = shared_layer_two(max_pool)\n","\n","    cbam_feature = layers.Add()([avg_pool, max_pool])\n","    cbam_feature = layers.Activation('sigmoid')(cbam_feature)\n","\n","    cbam_feature = layers.Multiply()([input_tensor, cbam_feature])\n","\n","    # Spatial attention\n","    avg_pool = layers.Lambda(lambda x: tf.reduce_mean(x, axis=-1, keepdims=True))(cbam_feature)\n","    max_pool = layers.Lambda(lambda x: tf.reduce_max(x, axis=-1, keepdims=True))(cbam_feature)\n","    concat = layers.Concatenate(axis=-1)([avg_pool, max_pool])\n","    cbam_feature = layers.Conv2D(filters=1, kernel_size=7, strides=1, padding='same', activation='sigmoid', kernel_initializer='he_normal', use_bias=False)(concat)\n","\n","    cbam_feature = layers.Multiply()([cbam_feature, cbam_feature])\n","\n","    return cbam_feature\n"],"metadata":{"id":"fKXP7oo5GRA3"},"id":"fKXP7oo5GRA3","execution_count":null,"outputs":[]},{"cell_type":"code","source":["def se_block(input_tensor, ratio=8):\n","    channel = input_tensor.shape[-1]\n","    se_feature = layers.GlobalAveragePooling2D()(input_tensor)\n","    se_feature = layers.Reshape((1, 1, channel))(se_feature)\n","    se_feature = layers.Dense(channel // ratio, activation='relu', kernel_initializer='he_normal', use_bias=True, bias_initializer='zeros')(se_feature)\n","    se_feature = layers.Dense(channel, activation='sigmoid', kernel_initializer='he_normal', use_bias=True, bias_initializer='zeros')(se_feature)\n","    se_feature = layers.Multiply()([input_tensor, se_feature])\n","    return se_feature\n"],"metadata":{"id":"1jS9ZbA7GTSo"},"id":"1jS9ZbA7GTSo","execution_count":null,"outputs":[]},{"cell_type":"code","source":["def scse_block(input_tensor, ratio=8):\n","    se_feature = se_block(input_tensor, ratio)\n","\n","    avg_pool = layers.Lambda(lambda x: tf.reduce_mean(x, axis=-1, keepdims=True))(input_tensor)\n","    max_pool = layers.Lambda(lambda x: tf.reduce_max(x, axis=-1, keepdims=True))(input_tensor)\n","    concat = layers.Concatenate(axis=-1)([avg_pool, max_pool])\n","    spatial_se = layers.Conv2D(filters=1, kernel_size=1, strides=1, padding='same', activation='sigmoid', kernel_initializer='he_normal', use_bias=False)(concat)\n","\n","    scse_feature = layers.Add()([layers.Multiply()([input_tensor, spatial_se]), se_feature])\n","\n","    return scse_feature\n"],"metadata":{"id":"ZSvo03PwGVs7"},"id":"ZSvo03PwGVs7","execution_count":null,"outputs":[]},{"cell_type":"code","source":["def unet_with_attention(input_shape):\n","    inputs = layers.Input(input_shape)\n","\n","    # Encoder\n","    c1 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n","    c1 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(c1)\n","    c1 = scse_block(c1)\n","    p1 = layers.MaxPooling2D((2, 2))(c1)\n","\n","    c2 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(p1)\n","    c2 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(c2)\n","    c2 = cbam_block(c2)\n","    p2 = layers.MaxPooling2D((2, 2))(c2)\n","\n","    c3 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(p2)\n","    c3 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(c3)\n","    c3 = scse_block(c3)\n","    p3 = layers.MaxPooling2D((2, 2))(c3)\n","\n","    c4 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(p3)\n","    c4 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(c4)\n","    c4 = cbam_block(c4)\n","    p4 = layers.MaxPooling2D((2, 2))(c4)\n","\n","    # Bottleneck\n","    c5 = layers.Conv2D(1024, (3, 3), activation='relu', padding='same')(p4)\n","    c5 = layers.Conv2D(1024, (3, 3), activation='relu', padding='same')(c5)\n","    c5 = scse_block(c5)\n","\n","    # Decoder\n","    u6 = layers.Conv2DTranspose(512, (2, 2), strides=(2, 2), padding='same')(c5)\n","    u6 = layers.concatenate([u6, c4])\n","    c6 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(u6)\n","    c6 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(c6)\n","    c6 = cbam_block(c6)\n","\n","    u7 = layers.Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(c6)\n","    u7 = layers.concatenate([u7, c3])\n","    c7 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(u7)\n","    c7 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(c7)\n","    c7 = scse_block(c7)\n","\n","    u8 = layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c7)\n","    u8 = layers.concatenate([u8, c2])\n","    c8 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(u8)\n","    c8 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(c8)\n","    c8 = cbam_block(c8)\n","\n","    u9 = layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c8)\n","    u9 = layers.concatenate([u9, c1])\n","    c9 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(u9)\n","    c9 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(c9)\n","    c9 = scse_block(c9)\n","\n","    outputs = layers.Conv2D(1, (1, 1), activation='sigmoid')(c9)\n","\n","    model = models.Model(inputs=[inputs], outputs=[outputs])\n","\n","    return model\n"],"metadata":{"id":"5H9y8VJuGXkf"},"id":"5H9y8VJuGXkf","execution_count":null,"outputs":[]},{"cell_type":"code","source":["class DataGen(Sequence):\n","    def __init__(self, ids, path, batch_size=2, image_size=256):\n","        self.ids = ids\n","        self.path = path\n","        self.batch_size = batch_size\n","        self.image_size = image_size\n","        self.on_epoch_end()\n","\n","    def __load__(self, id_name):\n","        image_path = os.path.join(self.path, \"images\", \"img\", id_name)\n","        mask_path = os.path.join(self.path, \"mask\", \"img\", id_name)\n","        image = cv2.imread(image_path)\n","        if image is None or image.size == 0:\n","            return None, None\n","        image = cv2.resize(image, (self.image_size, self.image_size)) / 255.0\n","\n","        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n","        if mask is None or mask.size == 0:\n","            return None, None\n","        mask = cv2.resize(mask, (self.image_size, self.image_size)) / 255.0\n","        mask = np.expand_dims(mask, axis=-1)\n","\n","        return image, mask\n","\n","    def __getitem__(self, index):\n","        files_batch = self.ids[index*self.batch_size : (index+1)*self.batch_size]\n","        images, masks = [], []\n","        for id_name in files_batch:\n","            img, msk = self.__load__(id_name)\n","            if img is not None and msk is not None:\n","                images.append(img)\n","                masks.append(msk)\n","        return np.array(images), np.array(masks)\n","\n","    def on_epoch_end(self):\n","        np.random.shuffle(self.ids)\n","\n","    def __len__(self):\n","        return int(np.ceil(len(self.ids) / float(self.batch_size)))"],"metadata":{"id":"Bd8aRIgf7-v8"},"id":"Bd8aRIgf7-v8","execution_count":null,"outputs":[]},{"cell_type":"code","source":["def iou(y_true, y_pred, smooth=1):\n","    intersection = K.sum(K.abs(y_true * y_pred), axis=[1,2,3])\n","    union = K.sum(y_true,[1,2,3])+K.sum(y_pred,[1,2,3])-intersection\n","    iou = K.mean((intersection + smooth) / (union + smooth), axis=0)\n","    return iou\n","\n","def F1(y_true, y_pred, smooth=1):\n","    intersection = K.sum(y_true * y_pred, axis=[1, 2, 3])\n","    union = K.sum(y_true, axis=[1, 2, 3]) + K.sum(y_pred, axis=[1, 2, 3])\n","    dice = K.mean((2. * intersection + smooth) / (union + smooth), axis=0)\n","    return dice\n","\n","def dice_coef(y_true, y_pred, smooth = 0.00001):\n","    y_true_f = K.flatten(y_true)\n","    y_pred_f = K.flatten(y_pred)\n","    intersection = K.sum(y_true_f * y_pred_f)\n","    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n","\n","def recall(y_true, y_pred):\n","    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n","    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n","    recall = true_positives / (possible_positives + K.epsilon())\n","    return recall\n","\n","def precision(y_true, y_pred):\n","    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n","    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n","    precision = true_positives / (predicted_positives + K.epsilon())\n","    return precision\n","\n","def dice_coef_loss(y_true, y_pred):\n","    return -dice_coef(y_true, y_pred)\n","\n","def dice_loss(y_true, y_pred):\n","    y_true_f = tf.keras.backend.flatten(y_true)\n","    y_pred_f = tf.keras.backend.flatten(y_pred)\n","    intersection = tf.keras.backend.sum(y_true_f * y_pred_f)\n","    return 1 - (2. * intersection + 1) / (tf.keras.backend.sum(y_true_f) + tf.keras.backend.sum(y_pred_f) + 1)\n","\n","def bce_dice_loss(y_true, y_pred):\n","    bce = tf.keras.losses.BinaryCrossentropy()(y_true, y_pred)\n","    dice = dice_loss(y_true, y_pred)\n","    return bce + dice\n","\n","#till here it is mostly redundant, below is real code but like i said, keep.\n","def load_test_data(test_path, image_size, batch_size=10):\n","    test_ids = os.listdir(os.path.join(test_path, \"images\", \"img\"))\n","    gen = DataGen(test_ids, test_path, batch_size=batch_size, image_size=image_size)\n","    print(\"Test Data Loaded\")\n","    return gen, len(test_ids)\n","\n","def scheduler(epoch, lr):\n","    if epoch < 30:\n","        lr = 0.001\n","        return lr\n","    if epoch < 50:\n","        return 0.0005\n","    return 0.0001\n","\n","def visualize_output(x, y, y_pred, tot, idx, fig, title_flag=False):\n","    contours1, hierarchy = cv2.findContours(y[0].astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n","    contours2, hierarchy = cv2.findContours(y_pred[0].astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n","    cv2.drawContours(x[0], contours1, -1, (0, 255, 0), 3)\n","    cv2.drawContours(x[0], contours2, -1, (255, 0, 0), 3)\n","    ax = fig.add_subplot(tot, 5, idx)\n","    ax.imshow(np.reshape(x[0], (image_size, image_size, 3)))\n","\n","def evaluate_model(gen, model):\n","    results = {}\n","    y_true_all = []\n","    y_pred_all = []\n","    num_tests = len(gen)\n","    for i in range(num_tests):\n","        x, y_true = gen[i]\n","        y_pred_prob = model.predict(x)\n","        y_pred = (y_pred_prob > 0.8).astype(int)\n","        y_true = (y_true > 0.5).astype(int)\n","        y_true_all.extend(y_true.flatten())\n","        y_pred_all.extend(y_pred.flatten())\n","    y_true_all = np.array(y_true_all)\n","    y_pred_all = np.array(y_pred_all)\n","    tn, fp, fn, tp = confusion_matrix(y_true_all, y_pred_all).ravel()\n","    precision = tp / (tp + fp)\n","    recall = tp / (tp + fn)\n","    specificity = tn / (tn + fp)\n","    iou = jaccard_score(y_true_all, y_pred_all)\n","    out = model.evaluate(gen, steps=num_tests)\n","    last_metric = out[-1]\n","    results = {\n","        'Precision': precision,\n","        'Recall': recall,\n","        'Specificity': specificity,\n","        'IoU': iou,\n","        'Eval Metric': last_metric\n","    }\n","    print(results)"],"metadata":{"id":"brOebFgU8IIS"},"id":"brOebFgU8IIS","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# class DataGen(Sequence):\n","#     def __init__(self, image_ids, path, batch_size, image_size):\n","#         self.image_ids = image_ids\n","#         self.path = path\n","#         self.batch_size = batch_size\n","#         self.image_size = image_size\n","#         self.on_epoch_end()\n","\n","#     def __len__(self):\n","#         return int(np.floor(len(self.image_ids) / self.batch_size))\n","\n","#     def __getitem__(self, index):\n","#         batch_ids = self.image_ids[index * self.batch_size:(index + 1) * self.batch_size]\n","#         images = np.zeros((self.batch_size, self.image_size, self.image_size, 3), dtype=np.float32)\n","#         masks = np.zeros((self.batch_size, self.image_size, self.image_size, 1), dtype=np.float32)\n","\n","#         for i, id in enumerate(batch_ids):\n","#             # Updated path construction for images\n","#             image_path = os.path.join(self.path, 'images',  id)\n","#             # Updated path construction for masks\n","#             mask_path = os.path.join(self.path, 'masks', id)\n","\n","#             # Debugging: Print paths\n","#             print(f\"Loading image: {image_path}\")\n","#             print(f\"Loading mask: {mask_path}\")\n","\n","#             image = img_to_array(load_img(image_path, target_size=(self.image_size, self.image_size)))\n","#             mask = img_to_array(load_img(mask_path, color_mode=\"grayscale\", target_size=(self.image_size, self.image_size)))\n","#             images[i] = image / 255.0\n","#             masks[i] = mask / 255.0\n","\n","#         return images, masks\n","\n","#     def on_epoch_end(self):\n","#         np.random.shuffle(self.image_ids)"],"metadata":{"id":"MiH1bZ7nn5XE"},"id":"MiH1bZ7nn5XE","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# def bce_dice_loss(y_true, y_pred):\n","#     bce = tf.keras.losses.BinaryCrossentropy()(y_true, y_pred)\n","#     y_true_f = tf.keras.backend.flatten(y_true)\n","#     y_pred_f = tf.keras.backend.flatten(y_pred)\n","#     intersection = tf.keras.backend.sum(y_true_f * y_pred_f)\n","#     dice_loss = 1 - (2. * intersection + 1) / (tf.keras.backend.sum(y_true_f) + tf.keras.backend.sum(y_pred_f) + 1)\n","#     return bce + dice_loss\n","\n","# def iou(y_true, y_pred, smooth=1):\n","#     intersection = tf.keras.backend.sum(tf.keras.backend.abs(y_true * y_pred), axis=[1, 2, 3])\n","#     union = tf.keras.backend.sum(y_true, axis=[1, 2, 3]) + tf.keras.backend.sum(y_pred, axis=[1, 2, 3]) - intersection\n","#     return tf.keras.backend.mean((intersection + smooth) / (union + smooth), axis=0)\n","\n","# def F1(y_true, y_pred, smooth=1):\n","#     intersection = tf.keras.backend.sum(y_true * y_pred, axis=[1, 2, 3])\n","#     union = tf.keras.backend.sum(y_true, axis=[1, 2, 3]) + tf.keras.backend.sum(y_pred, axis=[1, 2, 3])\n","#     return tf.keras.backend.mean((2. * intersection + smooth) / (union + smooth), axis=0)\n"],"metadata":{"id":"zop9ZAIFGchI"},"id":"zop9ZAIFGchI","execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_path = '/content/drive/MyDrive/sayandeep/Processed_Dataset/training/'  # Update this with the actual path\n","validation_path = '/content/drive/MyDrive/sayandeep/Processed_Dataset/validation/'\n","# Training parameters\n","batch_size = 16  # Adjust batch size as needed\n","image_size = 256  # Adjust image size as needed\n","epochs = 50  # Adjust number of epochs as needed\n","\n","# Load training and validation data\n","train_ids = os.listdir(os.path.join(train_path, \"images\", \"img\"))\n","val_ids = os.listdir(os.path.join(validation_path, \"images\", \"img\"))\n","\n","train_gen = DataGen(train_ids, train_path, batch_size=batch_size, image_size=image_size)\n","val_gen = DataGen(val_ids, validation_path, batch_size=batch_size, image_size=image_size)\n","\n","# Define the model\n","input_shape = (image_size, image_size, 3)\n","model = unet_with_attention(input_shape)\n","\n","# Compile the model\n","model.compile(optimizer='adam', loss=bce_dice_loss, metrics=['accuracy', iou, F1])\n","\n","# Callbacks\n","checkpoint = ModelCheckpoint('/content/drive/My Drive/sayandeep/sayandeep_unet_cbam_se_best_model.h5', save_best_only=True, monitor='val_loss', mode='min')\n","lr_scheduler = LearningRateScheduler(scheduler)\n","reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=0.00001)\n","\n","# Train the model\n","history = model.fit(\n","    train_gen,\n","    validation_data=val_gen,\n","    epochs=epochs,\n","    callbacks=[checkpoint, lr_scheduler, reduce_lr]\n",")\n","\n","model_save_path_tf = '/content/drive/My Drive/sayandeep/sayandeep_cbam_unet_se'\n","model.save(model_save_path_tf, save_format='tf')\n","print(f\"Model saved to {model_save_path_tf}\")\n"],"metadata":{"id":"hYO_Gnz_Ghxi","colab":{"base_uri":"https://localhost:8080/"},"outputId":"fe7ae71f-d861-41a6-98e8-9b54b5fe0adf","executionInfo":{"status":"ok","timestamp":1721033661674,"user_tz":-330,"elapsed":7810783,"user":{"displayName":"Amit Pandey","userId":"12754004734397015121"}}},"id":"hYO_Gnz_Ghxi","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","307/307 [==============================] - ETA: 0s - loss: 0.9725 - accuracy: 0.9693 - iou: 0.0686 - F1: 0.1191 "]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r307/307 [==============================] - 4443s 14s/step - loss: 0.9725 - accuracy: 0.9693 - iou: 0.0686 - F1: 0.1191 - val_loss: 0.9249 - val_accuracy: 0.9779 - val_iou: 0.0734 - val_F1: 0.1269 - lr: 0.0010\n","Epoch 2/50\n","307/307 [==============================] - 65s 212ms/step - loss: 0.9152 - accuracy: 0.9679 - iou: 0.0920 - F1: 0.1532 - val_loss: 0.9412 - val_accuracy: 0.9765 - val_iou: 0.0636 - val_F1: 0.1085 - lr: 0.0010\n","Epoch 3/50\n","307/307 [==============================] - 67s 219ms/step - loss: 0.9125 - accuracy: 0.9672 - iou: 0.0936 - F1: 0.1559 - val_loss: 0.8891 - val_accuracy: 0.9724 - val_iou: 0.0996 - val_F1: 0.1620 - lr: 0.0010\n","Epoch 4/50\n","307/307 [==============================] - 71s 229ms/step - loss: 0.8985 - accuracy: 0.9698 - iou: 0.0985 - F1: 0.1625 - val_loss: 0.8792 - val_accuracy: 0.9732 - val_iou: 0.1004 - val_F1: 0.1657 - lr: 0.0010\n","Epoch 5/50\n","307/307 [==============================] - 65s 208ms/step - loss: 0.8936 - accuracy: 0.9710 - iou: 0.1007 - F1: 0.1657 - val_loss: 0.8940 - val_accuracy: 0.9785 - val_iou: 0.0842 - val_F1: 0.1411 - lr: 0.0010\n","Epoch 6/50\n","307/307 [==============================] - 67s 219ms/step - loss: 0.8717 - accuracy: 0.9738 - iou: 0.1047 - F1: 0.1707 - val_loss: 0.8562 - val_accuracy: 0.9741 - val_iou: 0.1078 - val_F1: 0.1725 - lr: 0.0010\n","Epoch 7/50\n","307/307 [==============================] - 69s 220ms/step - loss: 0.8571 - accuracy: 0.9755 - iou: 0.1068 - F1: 0.1729 - val_loss: 0.8322 - val_accuracy: 0.9764 - val_iou: 0.1094 - val_F1: 0.1767 - lr: 0.0010\n","Epoch 8/50\n","307/307 [==============================] - 75s 243ms/step - loss: 0.8469 - accuracy: 0.9757 - iou: 0.1095 - F1: 0.1769 - val_loss: 0.8164 - val_accuracy: 0.9779 - val_iou: 0.1118 - val_F1: 0.1810 - lr: 0.0010\n","Epoch 9/50\n","307/307 [==============================] - 68s 222ms/step - loss: 0.8396 - accuracy: 0.9760 - iou: 0.1127 - F1: 0.1811 - val_loss: 0.8149 - val_accuracy: 0.9743 - val_iou: 0.1273 - val_F1: 0.2020 - lr: 0.0010\n","Epoch 10/50\n","307/307 [==============================] - 70s 225ms/step - loss: 0.8320 - accuracy: 0.9762 - iou: 0.1157 - F1: 0.1855 - val_loss: 0.8056 - val_accuracy: 0.9775 - val_iou: 0.1207 - val_F1: 0.1935 - lr: 0.0010\n","Epoch 11/50\n","307/307 [==============================] - 65s 210ms/step - loss: 0.8308 - accuracy: 0.9762 - iou: 0.1155 - F1: 0.1849 - val_loss: 0.8216 - val_accuracy: 0.9763 - val_iou: 0.1208 - val_F1: 0.1902 - lr: 0.0010\n","Epoch 12/50\n","307/307 [==============================] - 69s 224ms/step - loss: 0.8233 - accuracy: 0.9764 - iou: 0.1197 - F1: 0.1909 - val_loss: 0.8004 - val_accuracy: 0.9791 - val_iou: 0.1237 - val_F1: 0.1962 - lr: 0.0010\n","Epoch 13/50\n","307/307 [==============================] - 64s 208ms/step - loss: 0.8223 - accuracy: 0.9764 - iou: 0.1193 - F1: 0.1902 - val_loss: 0.8117 - val_accuracy: 0.9728 - val_iou: 0.1299 - val_F1: 0.2071 - lr: 0.0010\n","Epoch 14/50\n","307/307 [==============================] - 67s 219ms/step - loss: 0.8164 - accuracy: 0.9767 - iou: 0.1205 - F1: 0.1919 - val_loss: 0.7931 - val_accuracy: 0.9777 - val_iou: 0.1340 - val_F1: 0.2106 - lr: 0.0010\n","Epoch 15/50\n","307/307 [==============================] - 69s 221ms/step - loss: 0.8127 - accuracy: 0.9768 - iou: 0.1234 - F1: 0.1958 - val_loss: 0.7907 - val_accuracy: 0.9747 - val_iou: 0.1368 - val_F1: 0.2155 - lr: 0.0010\n","Epoch 16/50\n","307/307 [==============================] - 69s 222ms/step - loss: 0.8090 - accuracy: 0.9768 - iou: 0.1250 - F1: 0.1981 - val_loss: 0.7846 - val_accuracy: 0.9758 - val_iou: 0.1403 - val_F1: 0.2190 - lr: 0.0010\n","Epoch 17/50\n","307/307 [==============================] - 69s 223ms/step - loss: 0.7998 - accuracy: 0.9772 - iou: 0.1279 - F1: 0.2019 - val_loss: 0.7703 - val_accuracy: 0.9787 - val_iou: 0.1368 - val_F1: 0.2141 - lr: 0.0010\n","Epoch 18/50\n","307/307 [==============================] - 70s 224ms/step - loss: 0.7982 - accuracy: 0.9772 - iou: 0.1291 - F1: 0.2033 - val_loss: 0.7610 - val_accuracy: 0.9792 - val_iou: 0.1447 - val_F1: 0.2244 - lr: 0.0010\n","Epoch 19/50\n","307/307 [==============================] - 68s 220ms/step - loss: 0.7881 - accuracy: 0.9776 - iou: 0.1330 - F1: 0.2088 - val_loss: 0.7569 - val_accuracy: 0.9790 - val_iou: 0.1459 - val_F1: 0.2253 - lr: 0.0010\n","Epoch 20/50\n","307/307 [==============================] - 65s 208ms/step - loss: 0.7822 - accuracy: 0.9779 - iou: 0.1375 - F1: 0.2148 - val_loss: 0.7858 - val_accuracy: 0.9791 - val_iou: 0.1333 - val_F1: 0.2079 - lr: 0.0010\n","Epoch 21/50\n","307/307 [==============================] - 64s 207ms/step - loss: 0.7764 - accuracy: 0.9781 - iou: 0.1396 - F1: 0.2173 - val_loss: 0.7881 - val_accuracy: 0.9770 - val_iou: 0.1464 - val_F1: 0.2284 - lr: 0.0010\n","Epoch 22/50\n","307/307 [==============================] - 68s 221ms/step - loss: 0.7680 - accuracy: 0.9784 - iou: 0.1450 - F1: 0.2243 - val_loss: 0.7338 - val_accuracy: 0.9794 - val_iou: 0.1510 - val_F1: 0.2321 - lr: 0.0010\n","Epoch 23/50\n","307/307 [==============================] - 69s 220ms/step - loss: 0.7577 - accuracy: 0.9786 - iou: 0.1487 - F1: 0.2293 - val_loss: 0.7305 - val_accuracy: 0.9785 - val_iou: 0.1539 - val_F1: 0.2372 - lr: 0.0010\n","Epoch 24/50\n","307/307 [==============================] - 68s 219ms/step - loss: 0.7550 - accuracy: 0.9789 - iou: 0.1509 - F1: 0.2319 - val_loss: 0.7132 - val_accuracy: 0.9800 - val_iou: 0.1651 - val_F1: 0.2504 - lr: 0.0010\n","Epoch 25/50\n","307/307 [==============================] - 65s 208ms/step - loss: 0.7477 - accuracy: 0.9790 - iou: 0.1540 - F1: 0.2364 - val_loss: 0.7255 - val_accuracy: 0.9793 - val_iou: 0.1586 - val_F1: 0.2417 - lr: 0.0010\n","Epoch 26/50\n","307/307 [==============================] - 64s 208ms/step - loss: 0.7458 - accuracy: 0.9791 - iou: 0.1555 - F1: 0.2384 - val_loss: 0.7237 - val_accuracy: 0.9773 - val_iou: 0.1732 - val_F1: 0.2648 - lr: 0.0010\n","Epoch 27/50\n","307/307 [==============================] - 67s 218ms/step - loss: 0.7454 - accuracy: 0.9790 - iou: 0.1576 - F1: 0.2416 - val_loss: 0.7088 - val_accuracy: 0.9789 - val_iou: 0.1762 - val_F1: 0.2660 - lr: 0.0010\n","Epoch 28/50\n","307/307 [==============================] - 65s 208ms/step - loss: 0.7356 - accuracy: 0.9793 - iou: 0.1606 - F1: 0.2450 - val_loss: 0.7109 - val_accuracy: 0.9801 - val_iou: 0.1669 - val_F1: 0.2503 - lr: 0.0010\n","Epoch 29/50\n","307/307 [==============================] - 67s 217ms/step - loss: 0.7304 - accuracy: 0.9796 - iou: 0.1636 - F1: 0.2485 - val_loss: 0.7000 - val_accuracy: 0.9808 - val_iou: 0.1750 - val_F1: 0.2652 - lr: 0.0010\n","Epoch 30/50\n","307/307 [==============================] - 65s 208ms/step - loss: 0.7264 - accuracy: 0.9798 - iou: 0.1655 - F1: 0.2511 - val_loss: 0.7224 - val_accuracy: 0.9814 - val_iou: 0.1526 - val_F1: 0.2322 - lr: 0.0010\n","Epoch 31/50\n","307/307 [==============================] - 64s 208ms/step - loss: 0.7080 - accuracy: 0.9806 - iou: 0.1723 - F1: 0.2592 - val_loss: 0.7068 - val_accuracy: 0.9822 - val_iou: 0.1640 - val_F1: 0.2451 - lr: 5.0000e-04\n","Epoch 32/50\n","307/307 [==============================] - 69s 223ms/step - loss: 0.7034 - accuracy: 0.9807 - iou: 0.1739 - F1: 0.2610 - val_loss: 0.6929 - val_accuracy: 0.9814 - val_iou: 0.1689 - val_F1: 0.2537 - lr: 5.0000e-04\n","Epoch 33/50\n","307/307 [==============================] - 68s 218ms/step - loss: 0.6962 - accuracy: 0.9810 - iou: 0.1764 - F1: 0.2638 - val_loss: 0.6813 - val_accuracy: 0.9815 - val_iou: 0.1798 - val_F1: 0.2693 - lr: 5.0000e-04\n","Epoch 34/50\n","307/307 [==============================] - 64s 207ms/step - loss: 0.6936 - accuracy: 0.9811 - iou: 0.1782 - F1: 0.2664 - val_loss: 0.6872 - val_accuracy: 0.9815 - val_iou: 0.1800 - val_F1: 0.2696 - lr: 5.0000e-04\n","Epoch 35/50\n","307/307 [==============================] - 67s 219ms/step - loss: 0.6942 - accuracy: 0.9810 - iou: 0.1782 - F1: 0.2660 - val_loss: 0.6771 - val_accuracy: 0.9825 - val_iou: 0.1798 - val_F1: 0.2678 - lr: 5.0000e-04\n","Epoch 36/50\n","307/307 [==============================] - 65s 210ms/step - loss: 0.6915 - accuracy: 0.9812 - iou: 0.1788 - F1: 0.2668 - val_loss: 0.6829 - val_accuracy: 0.9797 - val_iou: 0.1903 - val_F1: 0.2832 - lr: 5.0000e-04\n","Epoch 37/50\n","307/307 [==============================] - 68s 222ms/step - loss: 0.6884 - accuracy: 0.9812 - iou: 0.1804 - F1: 0.2687 - val_loss: 0.6717 - val_accuracy: 0.9817 - val_iou: 0.1858 - val_F1: 0.2770 - lr: 5.0000e-04\n","Epoch 38/50\n","307/307 [==============================] - 69s 222ms/step - loss: 0.6855 - accuracy: 0.9813 - iou: 0.1829 - F1: 0.2721 - val_loss: 0.6712 - val_accuracy: 0.9813 - val_iou: 0.1866 - val_F1: 0.2753 - lr: 5.0000e-04\n","Epoch 39/50\n","307/307 [==============================] - 65s 210ms/step - loss: 0.6806 - accuracy: 0.9815 - iou: 0.1838 - F1: 0.2729 - val_loss: 0.6802 - val_accuracy: 0.9813 - val_iou: 0.1820 - val_F1: 0.2708 - lr: 5.0000e-04\n","Epoch 40/50\n","307/307 [==============================] - 69s 224ms/step - loss: 0.6849 - accuracy: 0.9813 - iou: 0.1823 - F1: 0.2711 - val_loss: 0.6590 - val_accuracy: 0.9816 - val_iou: 0.1956 - val_F1: 0.2881 - lr: 5.0000e-04\n","Epoch 41/50\n","307/307 [==============================] - 65s 209ms/step - loss: 0.6809 - accuracy: 0.9815 - iou: 0.1850 - F1: 0.2743 - val_loss: 0.6912 - val_accuracy: 0.9828 - val_iou: 0.1696 - val_F1: 0.2533 - lr: 5.0000e-04\n","Epoch 42/50\n","307/307 [==============================] - 64s 207ms/step - loss: 0.6783 - accuracy: 0.9816 - iou: 0.1845 - F1: 0.2735 - val_loss: 0.6628 - val_accuracy: 0.9813 - val_iou: 0.1902 - val_F1: 0.2816 - lr: 5.0000e-04\n","Epoch 43/50\n","307/307 [==============================] - 64s 208ms/step - loss: 0.6738 - accuracy: 0.9817 - iou: 0.1870 - F1: 0.2767 - val_loss: 0.6664 - val_accuracy: 0.9812 - val_iou: 0.1887 - val_F1: 0.2781 - lr: 5.0000e-04\n","Epoch 44/50\n","307/307 [==============================] - 64s 208ms/step - loss: 0.6762 - accuracy: 0.9816 - iou: 0.1866 - F1: 0.2767 - val_loss: 0.6651 - val_accuracy: 0.9824 - val_iou: 0.1870 - val_F1: 0.2741 - lr: 5.0000e-04\n","Epoch 45/50\n","307/307 [==============================] - 64s 207ms/step - loss: 0.6731 - accuracy: 0.9817 - iou: 0.1871 - F1: 0.2769 - val_loss: 0.6676 - val_accuracy: 0.9818 - val_iou: 0.1885 - val_F1: 0.2770 - lr: 5.0000e-04\n","Epoch 46/50\n","307/307 [==============================] - 64s 207ms/step - loss: 0.6745 - accuracy: 0.9816 - iou: 0.1868 - F1: 0.2766 - val_loss: 0.6676 - val_accuracy: 0.9811 - val_iou: 0.1933 - val_F1: 0.2841 - lr: 5.0000e-04\n","Epoch 47/50\n","307/307 [==============================] - 64s 208ms/step - loss: 0.6688 - accuracy: 0.9819 - iou: 0.1899 - F1: 0.2805 - val_loss: 0.6631 - val_accuracy: 0.9801 - val_iou: 0.2015 - val_F1: 0.2982 - lr: 5.0000e-04\n","Epoch 48/50\n","307/307 [==============================] - 63s 206ms/step - loss: 0.6693 - accuracy: 0.9819 - iou: 0.1900 - F1: 0.2805 - val_loss: 0.6647 - val_accuracy: 0.9816 - val_iou: 0.1938 - val_F1: 0.2849 - lr: 5.0000e-04\n","Epoch 49/50\n","307/307 [==============================] - 67s 218ms/step - loss: 0.6689 - accuracy: 0.9818 - iou: 0.1906 - F1: 0.2815 - val_loss: 0.6580 - val_accuracy: 0.9823 - val_iou: 0.1893 - val_F1: 0.2801 - lr: 5.0000e-04\n","Epoch 50/50\n","307/307 [==============================] - 70s 224ms/step - loss: 0.6650 - accuracy: 0.9819 - iou: 0.1912 - F1: 0.2823 - val_loss: 0.6505 - val_accuracy: 0.9817 - val_iou: 0.1935 - val_F1: 0.2870 - lr: 5.0000e-04\n","Model saved to /content/drive/My Drive/sayandeep/sayandeep_cbam_unet_se\n"]}]},{"cell_type":"code","source":["import os\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.models import load_model\n","from sklearn.metrics import confusion_matrix, jaccard_score, precision_score, recall_score\n","\n","# Custom loss and metrics functions\n","def bce_dice_loss(y_true, y_pred):\n","    bce = tf.keras.losses.BinaryCrossentropy()(y_true, y_pred)\n","    y_true_f = tf.keras.backend.flatten(y_true)\n","    y_pred_f = tf.keras.backend.flatten(y_pred)\n","    intersection = tf.keras.backend.sum(y_true_f * y_pred_f)\n","    dice_loss = 1 - (2. * intersection + 1) / (tf.keras.backend.sum(y_true_f) + tf.keras.backend.sum(y_pred_f) + 1)\n","    return bce + dice_loss\n","\n","def iou(y_true, y_pred, smooth=1):\n","    intersection = tf.keras.backend.sum(tf.keras.backend.abs(y_true * y_pred), axis=[1, 2, 3])\n","    union = tf.keras.backend.sum(y_true, axis=[1, 2, 3]) + tf.keras.backend.sum(y_pred, axis=[1, 2, 3]) - intersection\n","    return tf.keras.backend.mean((intersection + smooth) / (union + smooth), axis=0)\n","\n","def F1(y_true, y_pred, smooth=1):\n","    intersection = tf.keras.backend.sum(y_true * y_pred, axis=[1, 2, 3])\n","    union = tf.keras.backend.sum(y_true, axis=[1, 2, 3]) + tf.keras.backend.sum(y_pred, axis=[1, 2, 3])\n","    return tf.keras.backend.mean((2. * intersection + smooth) / (union + smooth), axis=0)\n","\n","# Function to load the saved model\n","def load_model_custom(model_save_path_tf):\n","    return tf.keras.models.load_model(model_save_path_tf, custom_objects={'bce_dice_loss': bce_dice_loss, 'iou': iou, 'F1': F1})\n","\n","# Evaluate the model\n","def evaluate_model(model, gen):\n","    results = {}\n","    y_true_all = []\n","    y_pred_all = []\n","    num_tests = len(gen)\n","    for i in range(num_tests):\n","        x, y_true = gen[i]\n","        y_pred_prob = model.predict(x)\n","        y_pred = (y_pred_prob > 0.5).astype(int)\n","        y_true = (y_true > 0.5).astype(int)\n","        y_true_all.extend(y_true.flatten())\n","        y_pred_all.extend(y_pred.flatten())\n","    y_true_all = np.array(y_true_all)\n","    y_pred_all = np.array(y_pred_all)\n","    tn, fp, fn, tp = confusion_matrix(y_true_all, y_pred_all).ravel()\n","    precision = precision_score(y_true_all, y_pred_all)\n","    recall = recall_score(y_true_all, y_pred_all)\n","    specificity = tn / (tn + fp)\n","    iou_score = jaccard_score(y_true_all, y_pred_all)\n","    out = model.evaluate(gen, steps=num_tests)\n","    last_metric = out[-1]\n","    results = {\n","        'Precision': precision,\n","        'Recall': recall,\n","        'Specificity': specificity,\n","        'IoU': iou_score,\n","        'Eval Metric': last_metric\n","    }\n","    return results\n","\n","# Example usage\n","model_save_path_tf = '/content/drive/My Drive/sayandeep/sayandeep_cbam_unet'  # Update this with your model path\n","test_path = '/content/drive/My Drive/sayandeep/Processed_Dataset/testing'  # Update this with the actual path\n","image_size = 256  # Adjust image size as needed\n","\n","# Load the model\n","model = load_model_custom(model_save_path_tf)\n","\n","# Load test data\n","test_gen, num_test_samples = load_test_data(test_path, image_size)\n","\n","# Evaluate the model\n","results = evaluate_model(model, test_gen)\n","print(\"Evaluation Results:\", results)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_eX4ooH1pUS8","executionInfo":{"status":"ok","timestamp":1721202888047,"user_tz":-330,"elapsed":255361,"user":{"displayName":"Amit Pandey","userId":"12754004734397015121"}},"outputId":"3133d04d-5955-4e95-dfe5-531809357167"},"id":"_eX4ooH1pUS8","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Test Data Loaded\n","1/1 [==============================] - 11s 11s/step\n","1/1 [==============================] - 0s 139ms/step\n","1/1 [==============================] - 0s 138ms/step\n","1/1 [==============================] - 0s 140ms/step\n","1/1 [==============================] - 0s 142ms/step\n","1/1 [==============================] - 0s 139ms/step\n","1/1 [==============================] - 0s 137ms/step\n","1/1 [==============================] - 0s 138ms/step\n","1/1 [==============================] - 0s 138ms/step\n","1/1 [==============================] - 0s 140ms/step\n","1/1 [==============================] - 0s 140ms/step\n","1/1 [==============================] - 0s 137ms/step\n","1/1 [==============================] - 0s 135ms/step\n","1/1 [==============================] - 0s 135ms/step\n","1/1 [==============================] - 0s 136ms/step\n","1/1 [==============================] - 0s 135ms/step\n","1/1 [==============================] - 0s 135ms/step\n","1/1 [==============================] - 0s 140ms/step\n","1/1 [==============================] - 0s 136ms/step\n","1/1 [==============================] - 0s 137ms/step\n","1/1 [==============================] - 0s 137ms/step\n","1/1 [==============================] - 0s 134ms/step\n","1/1 [==============================] - 0s 137ms/step\n","1/1 [==============================] - 0s 139ms/step\n","1/1 [==============================] - 0s 136ms/step\n","1/1 [==============================] - 0s 136ms/step\n","1/1 [==============================] - 6s 6s/step\n","27/27 [==============================] - 5s 136ms/step - loss: 0.3591 - iou: 0.5255 - F1: 0.6605 - accuracy: 0.9914\n","Evaluation Results: {'Precision': 0.7394526087496752, 'Recall': 0.7098953532505557, 'Specificity': 0.9959665260952612, 'IoU': 0.5678559346292971, 'Eval Metric': 0.9914266467094421}\n"]}]},{"cell_type":"code","source":["import os\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.models import load_model\n","from sklearn.metrics import confusion_matrix, jaccard_score, precision_score, recall_score\n","\n","# Custom loss and metrics functions\n","def bce_dice_loss(y_true, y_pred):\n","    bce = tf.keras.losses.BinaryCrossentropy()(y_true, y_pred)\n","    y_true_f = tf.keras.backend.flatten(y_true)\n","    y_pred_f = tf.keras.backend.flatten(y_pred)\n","    intersection = tf.keras.backend.sum(y_true_f * y_pred_f)\n","    dice_loss = 1 - (2. * intersection + 1) / (tf.keras.backend.sum(y_true_f) + tf.keras.backend.sum(y_pred_f) + 1)\n","    return bce + dice_loss\n","\n","def iou(y_true, y_pred, smooth=1):\n","    intersection = tf.keras.backend.sum(tf.keras.backend.abs(y_true * y_pred), axis=[1, 2, 3])\n","    union = tf.keras.backend.sum(y_true, axis=[1, 2, 3]) + tf.keras.backend.sum(y_pred, axis=[1, 2, 3]) - intersection\n","    return tf.keras.backend.mean((intersection + smooth) / (union + smooth), axis=0)\n","\n","def F1(y_true, y_pred, smooth=1):\n","    intersection = tf.keras.backend.sum(y_true * y_pred, axis=[1, 2, 3])\n","    union = tf.keras.backend.sum(y_true, axis=[1, 2, 3]) + tf.keras.backend.sum(y_pred, axis=[1, 2, 3])\n","    return tf.keras.backend.mean((2. * intersection + smooth) / (union + smooth), axis=0)\n","\n","# Function to load the saved model\n","def load_model_custom(model_save_path_tf):\n","    return tf.keras.models.load_model(model_save_path_tf, custom_objects={'bce_dice_loss': bce_dice_loss, 'iou': iou, 'F1': F1})\n","\n","# Evaluate the model\n","def evaluate_model(model, gen):\n","    results = {}\n","    y_true_all = []\n","    y_pred_all = []\n","    num_tests = len(gen)\n","    for i in range(num_tests):\n","        x, y_true = gen[i]\n","        y_pred_prob = model.predict(x)\n","        y_pred = (y_pred_prob > 0.5).astype(int)\n","        y_true = (y_true > 0.5).astype(int)\n","        y_true_all.extend(y_true.flatten())\n","        y_pred_all.extend(y_pred.flatten())\n","    y_true_all = np.array(y_true_all)\n","    y_pred_all = np.array(y_pred_all)\n","    tn, fp, fn, tp = confusion_matrix(y_true_all, y_pred_all).ravel()\n","    precision = precision_score(y_true_all, y_pred_all)\n","    recall = recall_score(y_true_all, y_pred_all)\n","    specificity = tn / (tn + fp)\n","    iou_score = jaccard_score(y_true_all, y_pred_all)\n","    out = model.evaluate(gen, steps=num_tests)\n","    last_metric = out[-1]\n","    results = {\n","        'Precision': precision,\n","        'Recall': recall,\n","        'Specificity': specificity,\n","        'IoU': iou_score,\n","        'Eval Metric': last_metric\n","    }\n","    return results\n","\n","# Example usage\n","model_save_path_tf = '/content/drive/My Drive/sayandeep/sayandeep_unet'  # Update this with your model path\n","test_path = '/content/drive/My Drive/sayandeep/Processed_Dataset/testing'  # Update this with the actual path\n","image_size = 256  # Adjust image size as needed\n","\n","# Load the model\n","model = load_model_custom(model_save_path_tf)\n","\n","# Load test data\n","test_gen, num_test_samples = load_test_data(test_path, image_size)\n","\n","# Evaluate the model\n","results = evaluate_model(model, test_gen)\n","print(\"Evaluation Results:\", results)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UrpmnT3GsQVy","executionInfo":{"status":"ok","timestamp":1721203058076,"user_tz":-330,"elapsed":71917,"user":{"displayName":"Amit Pandey","userId":"12754004734397015121"}},"outputId":"53d711f5-3a0f-478a-ed4f-56a17243a2d6"},"id":"UrpmnT3GsQVy","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Test Data Loaded\n","1/1 [==============================] - 10s 10s/step\n","1/1 [==============================] - 0s 27ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 27ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 7s 7s/step\n","27/27 [==============================] - 5s 164ms/step - loss: 0.0591 - accuracy: 0.9912\n","Evaluation Results: {'Precision': 0.7324245551561065, 'Recall': 0.7003524372390609, 'Specificity': 0.9958741965096503, 'IoU': 0.55766822958492, 'Eval Metric': 0.9911845326423645}\n"]}]},{"cell_type":"code","source":["import os\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.models import load_model\n","from sklearn.metrics import confusion_matrix, jaccard_score, precision_score, recall_score\n","\n","# Custom loss and metrics functions\n","def bce_dice_loss(y_true, y_pred):\n","    bce = tf.keras.losses.BinaryCrossentropy()(y_true, y_pred)\n","    y_true_f = tf.keras.backend.flatten(y_true)\n","    y_pred_f = tf.keras.backend.flatten(y_pred)\n","    intersection = tf.keras.backend.sum(y_true_f * y_pred_f)\n","    dice_loss = 1 - (2. * intersection + 1) / (tf.keras.backend.sum(y_true_f) + tf.keras.backend.sum(y_pred_f) + 1)\n","    return bce + dice_loss\n","\n","def iou(y_true, y_pred, smooth=1):\n","    intersection = tf.keras.backend.sum(tf.keras.backend.abs(y_true * y_pred), axis=[1, 2, 3])\n","    union = tf.keras.backend.sum(y_true, axis=[1, 2, 3]) + tf.keras.backend.sum(y_pred, axis=[1, 2, 3]) - intersection\n","    return tf.keras.backend.mean((intersection + smooth) / (union + smooth), axis=0)\n","\n","def F1(y_true, y_pred, smooth=1):\n","    intersection = tf.keras.backend.sum(y_true * y_pred, axis=[1, 2, 3])\n","    union = tf.keras.backend.sum(y_true, axis=[1, 2, 3]) + tf.keras.backend.sum(y_pred, axis=[1, 2, 3])\n","    return tf.keras.backend.mean((2. * intersection + smooth) / (union + smooth), axis=0)\n","\n","# Function to load the saved model\n","def load_model_custom(model_save_path_tf):\n","    return tf.keras.models.load_model(model_save_path_tf, custom_objects={'bce_dice_loss': bce_dice_loss, 'iou': iou, 'F1': F1})\n","\n","# Evaluate the model\n","def evaluate_model(model, gen):\n","    results = {}\n","    y_true_all = []\n","    y_pred_all = []\n","    num_tests = len(gen)\n","    for i in range(num_tests):\n","        x, y_true = gen[i]\n","        y_pred_prob = model.predict(x)\n","        y_pred = (y_pred_prob > 0.5).astype(int)\n","        y_true = (y_true > 0.5).astype(int)\n","        y_true_all.extend(y_true.flatten())\n","        y_pred_all.extend(y_pred.flatten())\n","    y_true_all = np.array(y_true_all)\n","    y_pred_all = np.array(y_pred_all)\n","    tn, fp, fn, tp = confusion_matrix(y_true_all, y_pred_all).ravel()\n","    precision = precision_score(y_true_all, y_pred_all)\n","    recall = recall_score(y_true_all, y_pred_all)\n","    specificity = tn / (tn + fp)\n","    iou_score = jaccard_score(y_true_all, y_pred_all)\n","    out = model.evaluate(gen, steps=num_tests)\n","    last_metric = out[-1]\n","    results = {\n","        'Precision': precision,\n","        'Recall': recall,\n","        'Specificity': specificity,\n","        'IoU': iou_score,\n","        'Eval Metric': last_metric\n","    }\n","    return results\n","\n","# Example usage\n","model_save_path_tf = '/content/drive/My Drive/sayandeep/sayandeep_unet_attention'  # Update this with your model path\n","test_path = '/content/drive/My Drive/sayandeep/Processed_Dataset/testing'  # Update this with the actual path\n","image_size = 256  # Adjust image size as needed\n","\n","# Load the model\n","model = load_model_custom(model_save_path_tf)\n","\n","# Load test data\n","test_gen, num_test_samples = load_test_data(test_path, image_size)\n","\n","# Evaluate the model\n","results = evaluate_model(model, test_gen)\n","print(\"Evaluation Results:\", results)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4UmLA5Swsx2s","executionInfo":{"status":"ok","timestamp":1721203194934,"user_tz":-330,"elapsed":62829,"user":{"displayName":"Amit Pandey","userId":"12754004734397015121"}},"outputId":"ae9f4e9a-11ae-447b-937a-27ff47615131"},"id":"4UmLA5Swsx2s","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Test Data Loaded\n","1/1 [==============================] - 1s 759ms/step\n","1/1 [==============================] - 0s 98ms/step\n","1/1 [==============================] - 0s 94ms/step\n","1/1 [==============================] - 0s 90ms/step\n","1/1 [==============================] - 0s 90ms/step\n","1/1 [==============================] - 0s 91ms/step\n","1/1 [==============================] - 0s 87ms/step\n","1/1 [==============================] - 0s 88ms/step\n","1/1 [==============================] - 0s 87ms/step\n","1/1 [==============================] - 0s 87ms/step\n","1/1 [==============================] - 0s 89ms/step\n","1/1 [==============================] - 0s 89ms/step\n","1/1 [==============================] - 0s 89ms/step\n","1/1 [==============================] - 0s 88ms/step\n","1/1 [==============================] - 0s 90ms/step\n","1/1 [==============================] - 0s 87ms/step\n","1/1 [==============================] - 0s 89ms/step\n","1/1 [==============================] - 0s 87ms/step\n","1/1 [==============================] - 0s 89ms/step\n","1/1 [==============================] - 0s 87ms/step\n","1/1 [==============================] - 0s 91ms/step\n","1/1 [==============================] - 0s 89ms/step\n","1/1 [==============================] - 0s 89ms/step\n","1/1 [==============================] - 0s 88ms/step\n","1/1 [==============================] - 0s 88ms/step\n","1/1 [==============================] - 0s 88ms/step\n","1/1 [==============================] - 0s 62ms/step\n","27/27 [==============================] - 4s 128ms/step - loss: 0.3616 - iou: 0.5223 - F1: 0.6546 - accuracy: 0.9919\n","Evaluation Results: {'Precision': 0.7962251842831981, 'Recall': 0.6618156843608234, 'Specificity': 0.9972687579589822, 'IoU': 0.5659563155714648, 'Eval Metric': 0.9919454455375671}\n"]}]},{"cell_type":"code","source":["import os\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.models import load_model\n","from sklearn.metrics import confusion_matrix, jaccard_score, precision_score, recall_score\n","\n","# Custom loss and metrics functions\n","def bce_dice_loss(y_true, y_pred):\n","    bce = tf.keras.losses.BinaryCrossentropy()(y_true, y_pred)\n","    y_true_f = tf.keras.backend.flatten(y_true)\n","    y_pred_f = tf.keras.backend.flatten(y_pred)\n","    intersection = tf.keras.backend.sum(y_true_f * y_pred_f)\n","    dice_loss = 1 - (2. * intersection + 1) / (tf.keras.backend.sum(y_true_f) + tf.keras.backend.sum(y_pred_f) + 1)\n","    return bce + dice_loss\n","\n","def iou(y_true, y_pred, smooth=1):\n","    intersection = tf.keras.backend.sum(tf.keras.backend.abs(y_true * y_pred), axis=[1, 2, 3])\n","    union = tf.keras.backend.sum(y_true, axis=[1, 2, 3]) + tf.keras.backend.sum(y_pred, axis=[1, 2, 3]) - intersection\n","    return tf.keras.backend.mean((intersection + smooth) / (union + smooth), axis=0)\n","\n","def F1(y_true, y_pred, smooth=1):\n","    intersection = tf.keras.backend.sum(y_true * y_pred, axis=[1, 2, 3])\n","    union = tf.keras.backend.sum(y_true, axis=[1, 2, 3]) + tf.keras.backend.sum(y_pred, axis=[1, 2, 3])\n","    return tf.keras.backend.mean((2. * intersection + smooth) / (union + smooth), axis=0)\n","\n","# Function to load the saved model\n","def load_model_custom(model_save_path_tf):\n","    return tf.keras.models.load_model(model_save_path_tf, custom_objects={'bce_dice_loss': bce_dice_loss, 'iou': iou, 'F1': F1})\n","\n","# Evaluate the model\n","def evaluate_model(model, gen):\n","    results = {}\n","    y_true_all = []\n","    y_pred_all = []\n","    num_tests = len(gen)\n","    for i in range(num_tests):\n","        x, y_true = gen[i]\n","        y_pred_prob = model.predict(x)\n","        y_pred = (y_pred_prob > 0.5).astype(int)\n","        y_true = (y_true > 0.5).astype(int)\n","        y_true_all.extend(y_true.flatten())\n","        y_pred_all.extend(y_pred.flatten())\n","    y_true_all = np.array(y_true_all)\n","    y_pred_all = np.array(y_pred_all)\n","    tn, fp, fn, tp = confusion_matrix(y_true_all, y_pred_all).ravel()\n","    precision = precision_score(y_true_all, y_pred_all)\n","    recall = recall_score(y_true_all, y_pred_all)\n","    specificity = tn / (tn + fp)\n","    iou_score = jaccard_score(y_true_all, y_pred_all)\n","    out = model.evaluate(gen, steps=num_tests)\n","    last_metric = out[-1]\n","    results = {\n","        'Precision': precision,\n","        'Recall': recall,\n","        'Specificity': specificity,\n","        'IoU': iou_score,\n","        'Eval Metric': last_metric\n","    }\n","    return results\n","\n","# Example usage\n","model_save_path_tf = '/content/drive/My Drive/sayandeep/sayandeep_cbam_unet_se'  # Update this with your model path\n","test_path = '/content/drive/My Drive/sayandeep/Processed_Dataset/testing'  # Update this with the actual path\n","image_size = 256  # Adjust image size as needed\n","\n","# Load the model\n","model = load_model_custom(model_save_path_tf)\n","\n","# Load test data\n","test_gen, num_test_samples = load_test_data(test_path, image_size)\n","\n","# Evaluate the model\n","results = evaluate_model(model, test_gen)\n","print(\"Evaluation Results:\", results)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DvK3iYVBtAi-","executionInfo":{"status":"ok","timestamp":1721203281520,"user_tz":-330,"elapsed":61773,"user":{"displayName":"Amit Pandey","userId":"12754004734397015121"}},"outputId":"229735a6-94ac-493d-c8d6-88a16546d4b8"},"id":"DvK3iYVBtAi-","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Test Data Loaded\n","1/1 [==============================] - 3s 3s/step\n","1/1 [==============================] - 0s 178ms/step\n","1/1 [==============================] - 0s 180ms/step\n","1/1 [==============================] - 0s 176ms/step\n","1/1 [==============================] - 0s 180ms/step\n","1/1 [==============================] - 0s 176ms/step\n","1/1 [==============================] - 0s 180ms/step\n","1/1 [==============================] - 0s 179ms/step\n","1/1 [==============================] - 0s 178ms/step\n","1/1 [==============================] - 0s 176ms/step\n","1/1 [==============================] - 0s 177ms/step\n","1/1 [==============================] - 0s 179ms/step\n","1/1 [==============================] - 0s 179ms/step\n","1/1 [==============================] - 0s 182ms/step\n","1/1 [==============================] - 0s 179ms/step\n","1/1 [==============================] - 0s 177ms/step\n","1/1 [==============================] - 0s 180ms/step\n","1/1 [==============================] - 0s 177ms/step\n","1/1 [==============================] - 0s 182ms/step\n","1/1 [==============================] - 0s 182ms/step\n","1/1 [==============================] - 0s 181ms/step\n","1/1 [==============================] - 0s 179ms/step\n","1/1 [==============================] - 0s 178ms/step\n","1/1 [==============================] - 0s 179ms/step\n","1/1 [==============================] - 0s 180ms/step\n","1/1 [==============================] - 0s 184ms/step\n","1/1 [==============================] - 1s 1s/step\n","27/27 [==============================] - 6s 166ms/step - loss: 0.7286 - accuracy: 0.9825 - iou: 0.1508 - F1: 0.2375\n","Evaluation Results: {'Precision': 0.43040817981086094, 'Recall': 0.3262339821793273, 'Specificity': 0.993038209351623, 'IoU': 0.22785995793789654, 'Eval Metric': 0.23753945529460907}\n"]}]},{"cell_type":"code","source":["import os\n","import numpy as np\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","from tensorflow.keras.models import load_model\n","from sklearn.metrics import confusion_matrix, jaccard_score, precision_score, recall_score\n","from tensorflow.keras.preprocessing.image import load_img, img_to_array\n","\n","# Custom loss and metrics functions\n","def bce_dice_loss(y_true, y_pred):\n","    bce = tf.keras.losses.BinaryCrossentropy()(y_true, y_pred)\n","    y_true_f = tf.keras.backend.flatten(y_true)\n","    y_pred_f = tf.keras.backend.flatten(y_pred)\n","    intersection = tf.keras.backend.sum(y_true_f * y_pred_f)\n","    dice_loss = 1 - (2. * intersection + 1) / (tf.keras.backend.sum(y_true_f) + tf.keras.backend.sum(y_pred_f) + 1)\n","    return bce + dice_loss\n","\n","def iou(y_true, y_pred, smooth=1):\n","    intersection = tf.keras.backend.sum(tf.keras.backend.abs(y_true * y_pred), axis=[1, 2, 3])\n","    union = tf.keras.backend.sum(y_true, axis=[1, 2, 3]) + tf.keras.backend.sum(y_pred, axis=[1, 2, 3]) - intersection\n","    return tf.keras.backend.mean((intersection + smooth) / (union + smooth), axis=0)\n","\n","def F1(y_true, y_pred, smooth=1):\n","    intersection = tf.keras.backend.sum(y_true * y_pred, axis=[1, 2, 3])\n","    union = tf.keras.backend.sum(y_true, axis=[1, 2, 3]) + tf.keras.backend.sum(y_pred, axis=[1, 2, 3])\n","    return tf.keras.backend.mean((2. * intersection + smooth) / (union + smooth), axis=0)\n","\n","# Function to load the saved model\n","def load_model_custom(model_save_path_tf):\n","    return tf.keras.models.load_model(model_save_path_tf, custom_objects={'bce_dice_loss': bce_dice_loss, 'iou': iou, 'F1': F1})\n","\n","\n","\n","# Function to load test data\n","def load_test_data(test_path, image_size, batch_size=10):\n","    test_ids = os.listdir(os.path.join(test_path, \"images\", \"img\"))\n","    gen = DataGen(test_ids, test_path, batch_size=batch_size, image_size=image_size)\n","    print(\"Test Data Loaded\")\n","    return gen, len(test_ids)\n","\n","# Evaluate the model\n","def evaluate_model(model, gen):\n","    results = {}\n","    y_true_all = []\n","    y_pred_all = []\n","    num_tests = len(gen)\n","    for i in range(num_tests):\n","        x, y_true = gen[i]\n","        y_pred_prob = model.predict(x)\n","        y_pred = (y_pred_prob > 0.5).astype(int)\n","        y_true = (y_true > 0.5).astype(int)\n","        y_true_all.extend(y_true.flatten())\n","        y_pred_all.extend(y_pred.flatten())\n","    y_true_all = np.array(y_true_all)\n","    y_pred_all = np.array(y_pred_all)\n","    tn, fp, fn, tp = confusion_matrix(y_true_all, y_pred_all).ravel()\n","    precision = precision_score(y_true_all, y_pred_all)\n","    recall = recall_score(y_true_all, y_pred_all)\n","    specificity = tn / (tn + fp)\n","    iou_score = jaccard_score(y_true_all, y_pred_all)\n","    out = model.evaluate(gen, steps=num_tests)\n","    last_metric = out[-1]\n","    results = {\n","        'Precision': precision,\n","        'Recall': recall,\n","        'Specificity': specificity,\n","        'IoU': iou_score,\n","        'Eval Metric': last_metric\n","    }\n","    return results\n","\n","# Visualize the model predictions\n","def visualize_predictions(model, gen, num_images=5):\n","    fig, axes = plt.subplots(num_images, 3, figsize=(15, num_images * 5))\n","    for i in range(num_images):\n","        x, y_true = gen[i]\n","        y_pred_prob = model.predict(x)\n","        y_pred = (y_pred_prob > 0.5).astype(int)\n","\n","        axes[i, 0].imshow(x[0])\n","        axes[i, 0].set_title(\"Input Image\")\n","        axes[i, 0].axis(\"off\")\n","\n","        axes[i, 1].imshow(y_true[0].squeeze(), cmap=\"gray\")\n","        axes[i, 1].set_title(\"True Mask\")\n","        axes[i, 1].axis(\"off\")\n","\n","        axes[i, 2].imshow(y_pred[0].squeeze(), cmap=\"gray\")\n","        axes[i, 2].set_title(\"Predicted Mask\")\n","        axes[i, 2].axis(\"off\")\n","\n","    plt.tight_layout()\n","    plt.show()\n","\n","# Example usage\n","model_save_path_tf = '/content/drive/My Drive/sayandeep/sayandeep_cbam_unet'  # Update this with your model path\n","test_path = '/content/drive/My Drive/sayandeep/Processed_Dataset/testing'  # Update this with the actual path\n","image_size = 256  # Adjust image size as needed\n","\n","# Load the model\n","model = load_model_custom(model_save_path_tf)\n","\n","# Load test data\n","test_gen, num_test_samples = load_test_data(test_path, image_size)\n","\n","# Evaluate the model\n","results = evaluate_model(model, test_gen)\n","print(\"Evaluation Results:\", results)\n","\n","# Visualize the predictions\n","visualize_predictions(model, test_gen, num_images=5)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":388},"id":"Fl5tJ7MCuDMM","executionInfo":{"status":"error","timestamp":1721757251249,"user_tz":-330,"elapsed":5636,"user":{"displayName":"Amit Pandey","userId":"12754004734397015121"}},"outputId":"9f899ebb-eecf-4cd1-d50c-d3bdb5248f0e"},"id":"Fl5tJ7MCuDMM","execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Test Data Loaded\n"]},{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/content/drive/My Drive/sayandeep/Processed_Dataset/testing/masks/mask/200.png'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-f47297f9d600>\u001b[0m in \u001b[0;36m<cell line: 107>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;31m# Evaluate the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Evaluation Results:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-7-f47297f9d600>\u001b[0m in \u001b[0;36mevaluate_model\u001b[0;34m(model, gen)\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0mnum_tests\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_tests\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0my_pred_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my_pred_prob\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-6-dbabedac5ba3>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m             \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__load__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m             \u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mmasks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-6-dbabedac5ba3>\u001b[0m in \u001b[0;36m__load__\u001b[0;34m(self, id_name)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m255.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"grayscale\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m255.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/image_utils.py\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, color_mode, target_size, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[1;32m    420\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m             \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpil_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/My Drive/sayandeep/Processed_Dataset/testing/masks/mask/200.png'"]}]},{"cell_type":"code","execution_count":null,"id":"SDnNsHMjidKV","metadata":{"id":"SDnNsHMjidKV"},"outputs":[],"source":["#Most important Code in the Entire Code. ALWAYS DO RUN ALL\n","from google.colab import runtime\n","runtime.unassign()"]},{"cell_type":"code","source":[],"metadata":{"id":"5Pge_DqY2F0Y"},"id":"5Pge_DqY2F0Y","execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.6"}},"nbformat":4,"nbformat_minor":5}